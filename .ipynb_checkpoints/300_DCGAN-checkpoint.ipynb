{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# 300. 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks, DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MbKJY38Puy9"
   },
   "source": [
    "## 생성적 적대 신경망(GANs) \n",
    "\n",
    "- [생성적 적대 신경망](https://arxiv.org/abs/1406.2661) (Generative Adversarial Networks, GANs)은 요즘 컴퓨터 과학에서 가장 흥미로운 아이디어 중 하나  \n",
    "- 두개의 모델이 적대적인 과정을 통해 동시에 훈련  \n",
    "- *생성자* (\"예술가\")는 진짜처럼 보이는 이미지를 생성하도록 배우는 와중에, *감별자* (\"예술비평가\")는 가짜의 이미지로부터 진짜를 구별하게 되는 것을 배우게 됨\n",
    "\n",
    "![생성자와 감별자를 그린 도표](https://tensorflow.org/tutorials/generative/images/gan1.png)\n",
    "\n",
    "\n",
    "\n",
    "- 훈련과정 동안 *생성자*는 점차 실제같은 이미지를 더 잘 생성  \n",
    "- *감별자*는 점차 진짜와 가짜를 더 잘 구별  \n",
    "- 이 과정은 *감별자*가 가짜 이미지에서 진짜 이미지를 더이상 구별하지 못하게 될때, 평형상태에 도달\n",
    "\n",
    "![생성자와 감별자를 그린 두번째 도표](https://tensorflow.org/tutorials/generative/images/gan2.png)\n",
    "\n",
    "- 이 과정을 MNIST 데이터를 이용하여 구현  \n",
    "- 아래의 애니메이션은 50 에포크(epoch)동안 훈련한 *생성자*가 생성해낸 연속된 이미지들을 보여줌  \n",
    "- 이미지들은 랜덤한 잡음으로 부터 시작되었고, 점차 시간이 지남에 따라 손으로 쓴 숫자들을 닮아가게 됨\n",
    "\n",
    "![출력 예시](https://tensorflow.org/images/gan/dcgan.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "# GIF를 만들기위해 설치\n",
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "#import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### 데이터셋 로딩 및 준비\n",
    "- 생성자와 감별자를 훈련하기위해 MNIST 데이터셋을 사용  \n",
    "- 생성자는 손글씨 숫자 데이터를 닮은 숫자들을 생성할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist dataset load\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "#(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 이미지에 dimension 더해주고 [-1, 1]로 정규화\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 \n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 배치를 만들고 섞음\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pxv2sUnnm3U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a8b84d438>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[100].reshape(28, 28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## 모델 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### 생성자\n",
    "\n",
    "- 생성자는 시드값 (seed; 랜덤한 잡음)으로부터 CNN 의 역순으로 이미지를 생성하기 위해, `tf.keras.layers.Conv2DTranspose` (inverse Convolution 을 통한 upsampling) 층을 이용  \n",
    "- stride=(2, 2) 일 경우 dimension 이 2 배로 upsampling 됨\n",
    "- 처음 `Dense`층은 시드값을 인풋으로 받음  \n",
    "- 그 다음 원하는 사이즈 28x28x1의 이미지가 나오도록 Conv2DTranspose 를 이용한 업샘플링을 여러번 함  \n",
    "- tanh를 사용하는 마지막 층을 제외한 나머지 각 층마다 활성함수로 `tf.keras.layers.LeakyReLU`을 사용하고 있음을 주목할 것\n",
    "\n",
    "<img src=\"GAN_Generator.png\" width=\"700\">\n",
    "\n",
    "- \"same\" padding and stride = 1, the output is the same size  \n",
    "- \"same\" padding and stride = 2, the output is double the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, \n",
    "                           input_shape=(100,)))   # seed 를 입력으로 받음, 출력 12544\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)          # 배치사이즈로 None 추가\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), \n",
    "                                     strides=(1, 1), padding='same', use_bias=False))  \n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "(아직 훈련이 되지않은) 생성자를 이용해 이미지를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiSikY24nm3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25a95f41470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGFpJREFUeJzt3XtwleW1BvBnJVyMAVGC3K9yERis1EZq4dR62gGtQ6W2Y1uZKlIt1KnTY8fp0GFqaztjRzvHU/uHQ6VHBxy11Y5wpNUqFgVUKBIuclVBihiIBEQkCOWSrPMHm85W+Z4Vk7D3dt7nN8OQ5Mm795edrOwk72WZu0NE0lNW7AsQkeJQ8YskSsUvkigVv0iiVPwiiVLxiyRKxS+SKBW/SKJU/CKJalfIO+vUqZNXVVVl5tFqw/bt22dmx44da/HY5owvK2v598mmpiaam1mr8sbGxswsuu7o2qLH7ejRozTv0KFDZhZ9XNG1Hz9+nObsY+vYsWOrbps95s3Bri16XNq1yy7bPXv2oKGhgd/AydtpzjtlMbMrAPwOQDmA/3X3u9j7V1VVYcaMGZl59IV47rnnZmZ79uyhY3v16kXz2tpamnfu3JnmzKFDh2heXl5O86gAGxoaMrPKyko69oMPPqB5jx49aL5z506as8c9KsBOnTrRvL6+nuaHDx/OzIYMGULHRl9P7DFvDvY1wYobAM4+++zM7Oc//3mzr6HFT2dmVg7gPgBfBTASwLVmNrKltycihdWa3/nHANjq7tvc/SiAPwGY1DaXJSKnW2uKvw+At/Ner8297UPMbJqZ1ZhZzcGDB1txdyLSllpT/Kf6o8LH/mLn7rPdvdrdq6Pf4USkcFpT/LUA+uW93hfArtZdjogUSmuKfyWAoWY2yMw6APgOgAVtc1kicrq1eKrP3Y+b2S0AnsWJqb4H3X0jG2NmdN53//799D4PHDiQme3YsYOO7d+/f4tvGwC6d++ema1fv56Ojaa03n33XZp/7Wtfo/m6desysyNHjtCxbN0FAOzdu5fm77//Ps3ZtNW+ffvo2K5du9J827ZtNB8xYkRmFk3t/utf/6J5dO1Rzh73aGqXfU6j6fJ8rZrnd/enATzdmtsQkeLQ8l6RRKn4RRKl4hdJlIpfJFEqfpFEqfhFElXQ/fwA374azY2eccYZmVm3bt3o2K1bt9J81KhRNGdbX0eO5JsZ+/btS/OXXnqJ5osWLaJ57969M7N+/fplZgDf9grE22qjeeUzzzwzM2vNNmkAOO+882jOPrZo/UM01x5tux0zZgzNKyoqMrNobQW7tk9y7oSe+UUSpeIXSZSKXyRRKn6RRKn4RRKl4hdJVMGn+tjUEJv+iPLVq1fTsdHUS7Stlk31RdOIb7zxBs1rampoPn36dJrff//9mdmXvvQlOpZtVQb40dsAsHbtWppffvnlmVm0DTs6cTmanmXTlCtWrKBjBw8eTPPly5fTPDqyjp08fMEFF9CxbAt3dOR4Pj3ziyRKxS+SKBW/SKJU/CKJUvGLJErFL5IoFb9Iogo+z8/06fOxbl8fMnDgwMwsarEdbbuNts2yDsFDhw6lY7t06ULz6Nqj47EnTJiQmUXbZqNus2wbNcDn8QFg+PDhmVm0dTU6Tn3XLt4jZuLEiZlZ1Bk5ahcfbQmOuh+z9S5vvvkmHcvaokfXnU/P/CKJUvGLJErFL5IoFb9IolT8IolS8YskSsUvkqhWzfOb2XYADQAaARx392r2/o2NjXjvvfcy80OHDtH7GzBgQGb2zjvv0LHRXHs0333++ednZtGR49Gc79NP80bH0d5ydl5A1OaazRkD8Z75VatW0Zx97IMGDaJjo2PBozba7JyFaD48WnsRXXv0uLLPS3TWAFt7EV13vrZY5POf7s5Xa4hIydGP/SKJam3xO4CFZrbKzKa1xQWJSGG09sf+ce6+y8y6A3jOzF5z96X575D7pjANAM4+++xW3p2ItJVWPfO7+67c//UA5gP42CmZ7j7b3avdvTrq+yYihdPi4jezSjPrfPJlABMAbGirCxOR06s1P/b3ADDfzE7ezqPu/kybXJWInHYtLn533wbgwk90Z+3a0X3x0dn7tbW1mVnHjh3p2OisgGhP/ssvv5yZRXveq6qqaP7LX/6S5tHHFq1xYCorK2kezaVH++JZX4Dt27fTsdGcddT6nLXRjm77hRdeoPnmzZtpfs8999Cc9UNobGykY9lamai1eD5N9YkkSsUvkigVv0iiVPwiiVLxiyRKxS+SqIIe3X3s2DHs3r07M4+2QbIjrBcvXkzHsmkfIG65zFpd33HHHXTsNddcQ/OoDXa03biuri4z+8lPfkLHzpo1i+Y33XQTzffv309zNvX08MMPt+q+N2zga8rYfe/cuZOOveqqq2getXSPWpfPmzcvMxs7diwdy6YCdXS3iIRU/CKJUvGLJErFL5IoFb9IolT8IolS8YskqqDz/OXl5fQorx49etDx7BjpiooKOrZ///40P378OM3ZGoQf//jHdGzPnj1p/uKLL9L8G9/4Bs3ZOoGolXS0ffTJJ5+k+ZQpU2heX1+fmV166aV0bLTt9qyzzqJ57qyJU4q2KkdrTqJt1tHXE7v/6GuVra2Itljn0zO/SKJU/CKJUvGLJErFL5IoFb9IolT8IolS8YskqqDz/JGyMv69iO3Jj47mjkT7r9lc++9//3s69je/+U2r7nvHjh00Z/v5o/UP7IwEgJ9jAACvvPIKzYcNG5aZjR49mo6N8mgunh31ztp3A8CkSZNoHrUPj+b52XqX6HyHZcuWZWZRO/h8euYXSZSKXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEhfP8ZvYggIkA6t19VO5tXQE8BmAggO0AvuXu2X2Dc8rKyug+aDYvC/C2yFGb7Gj/9uTJk1t838OHD6dj9+zZQ/MhQ4bQ/KKLLqL5888/n5l95jOfoWOjufLOnTvTPFonwB73aOxrr71G8/nz59OcrTGYMWMGHTtnzhyav/rqqzQfPHgwzW+55ZYW3zb7eonOGcjXnGf+OQCu+MjbfgpgkbsPBbAo97qIfIqExe/uSwHs+8ibJwGYm3t5LoCvt/F1ichp1tLf+Xu4ex0A5P7v3naXJCKFcNr/4Gdm08ysxsxqop5zIlI4LS3+3WbWCwBy/2ee0ujus9292t2roz8eiUjhtLT4FwA4eWzrFAD8iFcRKTlh8ZvZHwEsB3C+mdWa2Y0A7gIw3sy2ABife11EPkXCeX53vzYj+sonvTN3p+fER+eVHzx4MDOL/p4QzXdH59uz8+ejPfPs/HgAuO+++2g+a9YsmrP93zU1NXRsdFbA7bffTvPLL7+c5ldeeWVmtmLFCjo2+pxF6x9GjBiRmd1888107MSJE2leWVlJ82jdyYYNGzKzvn370rGsz0O0niWfVviJJErFL5IoFb9IolT8IolS8YskSsUvkqiCt+ju0qVLZs6O5gZ4S2bWthgA9u7dS/NoSmz69OmZ2aJFi+jY6BjnAQMG0Dw60pw9Lr1796Zjq6uraf7444/TfOrUqTRnR6r/4x//oGPZVB0ArFmzhuZsajjahh21Lo/arm/fvp3mTPT1wlrZRzWUT8/8IolS8YskSsUvkigVv0iiVPwiiVLxiyRKxS+SqJJq0c1aTQP8GOl33nmHjr344otpzlpwA8DSpUszs6jd8+uvv07zqBX16tWrac4+9mhb7JIlS2j+zW9+k+Z33303ze+8887MbMKECXRstD11+fLlNGdrDB555BE6Nlq7Ea0riY5rX7lyZWYWfc7OO++8zOypp56iY/PpmV8kUSp+kUSp+EUSpeIXSZSKXyRRKn6RRKn4RRJV0Hl+d8fhw4cz82jPfb9+/TKzbdu20bHR3vCdO3fSnM3rfvGLX6Rju3XrRvPFixfTfN++j/ZJ/bCBAwdmZtHH9YMf/IDmDz/8MM2vuuoqmrPPd2uOqAaACy+8kOaf//znM7No/cJzzz1H82g+/Uc/+hHN2eds9+7ddCzLoyPo8+mZXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEqfhFEhXO85vZgwAmAqh391G5t90B4PsATm5anunuT0e3FbXoZvP4AFBbW5uZRS2Vo7nT9evX03zUqFGZ2fz58+nYyZMn03zevHk0v/HGG2nO2j1PmjSJjr3//vtpHu2pj+bim5qaMrOFCxfSsd/97ndpHq2PYK3RDx06RMcOHTqU5tEahU2bNtH83Xffzcw++OADOpb1UmC3+1HNeeafA+CKU7z9t+4+OvcvLHwRKS1h8bv7UgB8iZmIfOq05nf+W8xsnZk9aGbntNkViUhBtLT4ZwEYDGA0gDoA92S9o5lNM7MaM6tpaGho4d2JSFtrUfG7+253b3T3JgB/ADCGvO9sd69292p2AKeIFFaLit/MeuW9ejWA7D83i0hJas5U3x8BXAagm5nVAvgFgMvMbDQAB7AdQHb/ahEpSebuBbuzIUOG+D33ZP55APX19XT84MGDM7NVq1bRscOGDaN5NJ/doUOHzCzaM9+xY0eab968uVXj2Tnu0VkD0fnyr776Ks27du1KczZnzR5TgH++AWDZsmU0r6qqysyiPvZjx46l+a9//WuaDxo0iOZsP3/Ug+LAgQOZ2QMPPIC6urrsBQ55tMJPJFEqfpFEqfhFEqXiF0mUil8kUSp+kUQV/OjuY8eOZeYVFRV0/K5duzKzaHvopZdeSvPoqObbbrstM/vVr35Fx0ZbNNmUFBAfj33vvfdmZueeey4du27dOpofPHiQ5pHWHDMdTfWVl5fTfOPGjZnZt7/9bTo2aqsebfk988wzab5mzZrMjE3dAvzjjqYw8+mZXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEqfhFElXQeX4zQ/v27TPzV155hY7v1KlTZjZ+/Hg6Njqa+6yzzqL5nDlzMrNonn76dH7cwerVq2keXTs7rjlq73311VfT/O9//zvNo9OZRo8enZm1pi06ACxatIjm119/fWbGjoEH4jUIdXV1NI/ah3/ve9/LzKI1K9H6hubSM79IolT8IolS8YskSsUvkigVv0iiVPwiiVLxiySqoPP8R44cwdatWzPzw4cPt/i22XHGAJ9vBoCHHnqI5lOnTs3MWNtxAJg7dy7Noz330Z76cePGZWbRtf3lL3+h+fDhw2nOjqAGgOeffz4ze+yxx+jYaO0GOxsC4OsE3nrrLTq2W7duNGct24F4X/2f//znzGzIkCF0LFv3ET0m+fTML5IoFb9IolT8IolS8YskSsUvkigVv0iiVPwiiQrn+c2sH4CHAPQE0ARgtrv/zsy6AngMwEAA2wF8y93fY7fVvn179OjRIzOP5qTZXP2mTZvo2GgNQbS/m80LR2cBROfPP/vsszS/++67ac56Dpx//vl0bE1NDc1ZrwQAKCvjzx8sj9qHR70Wevfu3eJ8yZIldOyXv/xlmjc1NdE8arPN5vKjdR/9+/fPzKK25/ma88x/HMBt7j4CwCUAfmhmIwH8FMAidx8KYFHudRH5lAiL393r3H117uUGAJsB9AEwCcDJpWtzAXz9dF2kiLS9T/Q7v5kNBPBZACsA9HD3OuDENwgA3dv64kTk9Gl28ZtZJwBPALjV3flC+g+Pm2ZmNWZWE62/F5HCaVbxm1l7nCj8R9x9Xu7Nu82sVy7vBaD+VGPdfba7V7t7dfSHMREpnLD4zcwAPABgs7v/T160AMCU3MtTADzZ9pcnIqdLc7b0jgNwHYD1ZrY297aZAO4C8LiZ3QhgB4Brohs6duwY9u7dm5mzI6gBPgUSbXuN2h5HbbBHjBiRmd133310bPQTz+c+9zmaP/HEEzT/5z//mZk988wzdGx09PbIkSNpvmDBApp37579p6Bo22yUv/zyyzRn21u3bNlCx0ZfT1Hb9RPPmdnYll93p2PPOeecFt3ux943egd3fwlA1kfylWbfk4iUFK3wE0mUil8kUSp+kUSp+EUSpeIXSZSKXyRRBT26u7y8nM4rs+2+APC3v/0tM4u2lkatpqO2x2+++WZmVllZScdGbbCjFtxHjx5tcX7rrbe26rZXrVpF82gNA1sf0a9fPzo2asFdUVFB8z179mRmN910Ex1bX3/KBav/tmzZMppfcsklNGfz8dE2ataqPtoWn0/P/CKJUvGLJErFL5IoFb9IolT8IolS8YskSsUvkqiCzvO3a9cOXbt2zczZvCzA55TXrl2bmQHxUcw333wzzZ966qnMjO2nB4Bt27bRfPPmzTQfNmwYzZkXXniB5m+88QbNo+Oxo/MC2H7+G264gY5dvHgxzaN1AKyNdtSafMqUKTSP9uuPGTOG5hs2bMjMouPW2TkGmucXkZCKXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFEFXSev7GxEe+//35mPmDAADo+OiudaWhooPnMmTNpzvZfV1dX07HROoCOHTvSfODAgTR/773szujRfvvoMb/gggtoPn78eJqvWbMmM5sxYwYde+jQIZqz8+sBvu89esyj9Q9Rj4mVK1fSnH1N7N+/n45l6wDOOOMMOjafnvlFEqXiF0mUil8kUSp+kUSp+EUSpeIXSZSKXyRR4Ty/mfUD8BCAngCaAMx299+Z2R0Avg/g5Cb8me7+NLutxsZG2ve8traWXsvOnTszs8OHD9Ox0RqBLl260Jz1DPjCF75Ax7K5boD3BACAK664guZsXjg6C2DFihU0v/DCC2k+b948mrM56ahnwMiRI2nO9rUDQJ8+fTKzJUuW0LE/+9nPaL58+fIW3zfA5+Oj9Q0HDhzIzD7Jfv7mLPI5DuA2d19tZp0BrDKz53LZb939v5t9byJSMsLid/c6AHW5lxvMbDMA/m1NREreJ/qd38wGAvgsgJM/K95iZuvM7EEzO+VaSzObZmY1ZlbDfuQXkcJqdvGbWScATwC41d0PAJgFYDCA0Tjxk8E9pxrn7rPdvdrdq9laaxEprGYVv5m1x4nCf8Td5wGAu+9290Z3bwLwBwD8xEIRKSlh8duJY0ofALDZ3f8n7+298t7tagDZx5GKSMlpzl/7xwG4DsB6Mzt5PvZMANea2WgADmA7gOnRDZWVldF21tE2yKFDh9LbZqqqqmgebQ89cuRIZhZNI06dOpXmjz76KM0XLlxIczad1rdvXzp28uTJNI+mnS6++GKas2mpsWPH0rFRm+zjx4/TnLVdv/322+nYaCpv3bp1NO/QoQPN2eP61ltv0bH9+/fPzJqamujYfM35a/9LAE51SDmd0xeR0qYVfiKJUvGLJErFL5IoFb9IolT8IolS8YskqqBHd5eVlaGioiIzHzFiBB3PjqiO5nyjedctW7bQnLWq3rRpEx37+uuv03zr1q00HzduHM3/+te/ZmbHjh2jY5999lmaX3fddTR/7bXXaM5asi9dupSOHTRoEM0jGzduzMz27dtHx/bs2ZPmbA0BALz99ts0X7ZsWWZ2/fXX07Hs6y2qg3x65hdJlIpfJFEqfpFEqfhFEqXiF0mUil8kUSp+kUSZuxfuzsz2AMjfrNwNwN6CXcAnU6rXVqrXBejaWqotr22Au5/bnHcsaPF/7M7NatydN7cvklK9tlK9LkDX1lLFujb92C+SKBW/SKKKXfyzi3z/TKleW6leF6Bra6miXFtRf+cXkeIp9jO/iBRJUYrfzK4ws9fNbKuZ/bQY15DFzLab2XozW2tmNUW+lgfNrN7MNuS9rauZPWdmW3L/8zPHC3ttd5jZztxjt9bMrizStfUzsxfMbLOZbTSz/8q9vaiPHbmuojxuBf+x38zKAbwBYDyAWgArAVzr7nxTfIGY2XYA1e5e9DlhM7sUwEEAD7n7qNzbfgNgn7vflfvGeY67zyiRa7sDwMFid27ONZTpld9ZGsDXAdyAIj525Lq+hSI8bsV45h8DYKu7b3P3owD+BGBSEa6j5Ln7UgAfPXViEoC5uZfn4sQXT8FlXFtJcPc6d1+de7kBwMnO0kV97Mh1FUUxir8PgPxjTmpRWi2/HcBCM1tlZtOKfTGn0CPXNv1k+/TuRb6ejwo7NxfSRzpLl8xj15KO122tGMV/qu4/pTTlMM7dLwLwVQA/zP14K83TrM7NhXKKztIloaUdr9taMYq/FkC/vNf7AthVhOs4JXfflfu/HsB8lF734d0nm6Tm/ucN7QqolDo3n6qzNErgsSuljtfFKP6VAIaa2SAz6wDgOwAWFOE6PsbMKnN/iIGZVQKYgNLrPrwAwJTcy1MAPFnEa/mQUuncnNVZGkV+7Eqt43VRFvnkpjLuBVAO4EF3v7PgF3EKZnYeTjzbAydONn60mNdmZn8EcBlO7PraDeAXAP4PwOMA+gPYAeAady/4H94yru0ynPjR9d+dm0/+jl3ga/sPAC8CWA/gZNvamTjx+3XRHjtyXdeiCI+bVviJJEor/EQSpeIXSZSKXyRRKn6RRKn4RRKl4hdJlIpfJFEqfpFE/T+r5jvO86e90QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### 감별자 \n",
    "- 감별자는 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류기\n",
    "- MNIST dataset 은 input_shape (28, 28, 1)  \n",
    "- sigmoid output 은 probability scalar 값  \n",
    "- CNN 과의 차이 : pooling layer 없고, stride 를 통하여 downsampling  \n",
    "\n",
    "<img src=\"GAN_Discriminator.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), \n",
    "                            strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhPneagzCaQv"
   },
   "source": [
    "- (아직까지 훈련이 되지 않은) 감별자를 사용하여, 생성된 이미지가 진짜인지 가짜인지 판별  \n",
    "- 모델은 진짜 이미지에는 양수의 값 (positive values)을, 가짜 이미지에는 음수의 값 (negative values)을 출력하도록 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxUOZ_Nbnm3h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 256)         819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 512)         3277312   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 4,305,409\n",
      "Trainable params: 4,305,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkA05NE6QMs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00062716]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## 손실함수와 옵티마이저 정의\n",
    "- 두 모델의 손실함수와 옵티마이저를 정의  \n",
    "- Discriminator 의 output 이 sigmoid 이므로, binary crossentropy 를 loss function 으로 사용 \n",
    "- from_logits=True 로 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### 감별자 손실함수 \n",
    "\n",
    "- 감별자가 가짜 이미지에서 얼마나 진짜 이미지를 잘 판별하는지 수치화하는 함수  \n",
    "- 진짜 이미지에 대한 감별자의 예측과 1로 이루어진 행렬을 비교하고, 가짜 (생성된) 이미지에 대한 감별자의 예측과 0으로 이루어진 행렬을 비교  \n",
    "- shape 은 (256, 1) $\\rightarrow$ BATCHSIZE\n",
    "- real image 는 label [11111..111], fake image 는 label [00000....000] 이 ground truth  \n",
    "- discriminator 는 real 은 real 로, fake 는 fake 로 바르게 판별해야 하므로 real_loss + fake_loss 가 minimize 되도록 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### 생성자 손실함수\n",
    "\n",
    "- 감별자를 얼마나 잘 속였는지에 대해 수치화  \n",
    "- 직관적으로 생성자가 원활히 수행되고 있다면, 감별자는 가짜 이미지를 진짜 (또는 1)로 분류를 할 것임. \n",
    "- 여기서 우리는 생성된 이미지에 대한 감별자의 결정(fake_output)을 1로 이루어진 행렬과 비교를 할 것임 (감별자가 감별한 결과가 모두 1 이 되어야 생성자가 감별자를 완벽히 속인 것임)\n",
    "- fake_output = discriminator(generated_images, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "### 감별자와 생성자는 따로 훈련되기 때문에, 감별자와 생성자의 옵티마이저는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### 체크포인트 저장\n",
    "\n",
    "- optimizer 와 model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEGjn3b5tPi9"
   },
   "outputs": [],
   "source": [
    "tf.train.Checkpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## 훈련 루프 정의\n",
    "\n",
    "- 훈련 루프는 생성자가 입력으로 랜덤시드를 받는 것으로부터 시작  \n",
    "- 그 시드값을 사용하여 이미지를 생성  \n",
    "- 감별자를 사용하여 (훈련 세트에서 갖고온) 진짜 이미지와 (생성자가 생성해낸) 가짜이미지를 분류  \n",
    "- 각 모델의 손실을 계산하고, 그래디언트 (gradients)를 사용해 생성자와 감별자를 업데이트\n",
    "<img src=\"adverseModel.png\" width=\"500\">\n",
    "\n",
    "## Training\n",
    "\n",
    "<img src=\"GANtraining.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# 이 시드를 시간이 지나도 재활용 (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# `tf.function` 데코레이터는 함수를 \"컴파일\"\n",
    "# 두개 module 의 gradient 를 따로 tracking 함\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)     # noise 에서 fake image 생성 \n",
    "\n",
    "        real_output = discriminator(images, training=True)       # real image 에 대한 감별자의 output\n",
    "        fake_output = discriminator(generated_images, training=True)  # fake image 에 대한 감별자의 output\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)   # fake image 에 대한 감별자의 output 을 all 1 로 만들기 위한 생성자 손실함수\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)  # real image 와 fake image 의 total loss 를 minimize 하기 위한 감별자 손실함수\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)  # 손실함수와 trainable parameter 지정\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))   # gradient update\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # GIF를 위한 이미지를 바로 생성\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        # 15 에포크가 지날 때마다 모델을 저장\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "        print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
    "        \n",
    "    # 마지막 에포크가 끝난 후 생성\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**이미지 생성 및 저장**\n",
    "\n",
    "-`training`이 False로 맞춰진 것을 주목. 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## 모델 훈련\n",
    "- 위에 정의된 `train()` 메서드를 생성자와 감별자를 동시에 훈련하기 위해 호출  \n",
    "- 생성적 적대 신경망을 학습하는 것은 매우 까다로울 수 있dma. 생성자와 감별자가 서로를 제압하지 않는 것이 중요 (예를 들어 학습률이 비슷하면 한쪽이 우세해짐.)\n",
    "- 훈련 초반부에는 생성된 이미지는 랜덤한 노이즈처럼 보이나 훈련이 진행될수록, 생성된 숫자는 점차 진짜처럼 보임  \n",
    "- 약 50 에포크가 지난 후, MNIST 숫자와 닮은 이미지가 생성  \n",
    "- 코랩에서 기본 설정으로 실행하면, 에포크마다 1분정도 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "마지막 체크포인트를 복구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7neLmBBhxbgR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## GIF 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# 에포크 숫자를 사용하여 하나의 이미지를 보여준다\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TMHTuisnm4J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "99-93.DCGAN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
