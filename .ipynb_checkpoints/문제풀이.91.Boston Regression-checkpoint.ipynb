{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습\n",
    "\n",
    "### UCI Machine Learning Repository 의 Auto MPG dataset 을 사용하여 Regression 예측 model 작성\n",
    "\n",
    "auto-mpg.data - data file  \n",
    "auto-mpg.names - data 설명 file\n",
    "\n",
    "1. mpg:           continuous  \n",
    "2. cylinders:     multi-valued discrete  \n",
    "3. displacement:  continuous (배기량)   \n",
    "4. horsepower:    continuous  \n",
    "5. weight:        continuous  \n",
    "6. acceleration:  continuous  \n",
    "7. model year:    multi-valued discrete  \n",
    "8. origin:        multi-valued discrete, 1 - USA, 2 - Europe, 3 - Japan  \n",
    "9. car name:      string (unique for each instance)  \n",
    "\n",
    "Missing Attribute Values:  horsepower has 6 missing values  ==> \"?\" 로 들어 있으므로 read_csv 시 nan 으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load 및 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = keras.utils.get_file(\"auto-mpg.data\", \n",
    "                                 \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "\n",
    "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin']\n",
    "\n",
    "rawdata = pd.read_csv(data_path, names=column_names, na_values=\"?\", comment=\"\\t\", sep=\" \", skipinitialspace=True)\n",
    "\n",
    "rawdata.dropna(inplace=True)\n",
    "\n",
    "data = rawdata.copy()\n",
    "\n",
    "data = pd.get_dummies(data, columns=['cylinders', 'origin'])\n",
    "\n",
    "label = data.pop('mpg')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.values, label.values)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model Build\n",
    "\n",
    "### train\n",
    "\n",
    "### predict\n",
    "\n",
    "### $r^2$ 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(32, input_shape=(13,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 294 samples, validate on 98 samples\n",
      "Epoch 1/500\n",
      "294/294 [==============================] - 1s 3ms/sample - loss: 593.9555 - mse: 593.9554 - val_loss: 565.1851 - val_mse: 565.1851\n",
      "Epoch 2/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 583.6793 - mse: 583.6793 - val_loss: 555.1783 - val_mse: 555.1783\n",
      "Epoch 3/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 573.4260 - mse: 573.4260 - val_loss: 545.0686 - val_mse: 545.0686\n",
      "Epoch 4/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 563.0107 - mse: 563.0106 - val_loss: 534.7925 - val_mse: 534.7925\n",
      "Epoch 5/500\n",
      "294/294 [==============================] - 0s 92us/sample - loss: 552.4199 - mse: 552.4199 - val_loss: 524.2574 - val_mse: 524.2574\n",
      "Epoch 6/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 541.4263 - mse: 541.4263 - val_loss: 513.3456 - val_mse: 513.3456\n",
      "Epoch 7/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 530.1084 - mse: 530.1084 - val_loss: 501.9203 - val_mse: 501.9203\n",
      "Epoch 8/500\n",
      "294/294 [==============================] - 0s 92us/sample - loss: 518.2184 - mse: 518.2185 - val_loss: 489.8842 - val_mse: 489.8842\n",
      "Epoch 9/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 505.7264 - mse: 505.7265 - val_loss: 477.1346 - val_mse: 477.1346\n",
      "Epoch 10/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 492.2316 - mse: 492.2316 - val_loss: 463.5393 - val_mse: 463.5393\n",
      "Epoch 11/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 477.9418 - mse: 477.9418 - val_loss: 448.8633 - val_mse: 448.8633\n",
      "Epoch 12/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 462.8807 - mse: 462.8806 - val_loss: 433.1880 - val_mse: 433.1880\n",
      "Epoch 13/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 446.3252 - mse: 446.3252 - val_loss: 416.5856 - val_mse: 416.5856\n",
      "Epoch 14/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 429.0080 - mse: 429.0080 - val_loss: 398.9427 - val_mse: 398.9427\n",
      "Epoch 15/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 410.3752 - mse: 410.3752 - val_loss: 380.2458 - val_mse: 380.2458\n",
      "Epoch 16/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 391.0597 - mse: 391.0597 - val_loss: 360.4479 - val_mse: 360.4479\n",
      "Epoch 17/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 370.4010 - mse: 370.4010 - val_loss: 339.7763 - val_mse: 339.7763\n",
      "Epoch 18/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 348.6583 - mse: 348.6583 - val_loss: 318.3626 - val_mse: 318.3626\n",
      "Epoch 19/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 326.2349 - mse: 326.2349 - val_loss: 296.2808 - val_mse: 296.2808\n",
      "Epoch 20/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 303.7386 - mse: 303.7386 - val_loss: 273.5441 - val_mse: 273.5441\n",
      "Epoch 21/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 280.1459 - mse: 280.1459 - val_loss: 250.7149 - val_mse: 250.7149\n",
      "Epoch 22/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 256.9275 - mse: 256.9275 - val_loss: 227.9093 - val_mse: 227.9093\n",
      "Epoch 23/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 232.6743 - mse: 232.6743 - val_loss: 205.4194 - val_mse: 205.4194\n",
      "Epoch 24/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 210.2985 - mse: 210.2985 - val_loss: 183.2434 - val_mse: 183.2434\n",
      "Epoch 25/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 187.1408 - mse: 187.1408 - val_loss: 162.0071 - val_mse: 162.0071\n",
      "Epoch 26/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 165.3514 - mse: 165.3514 - val_loss: 141.7997 - val_mse: 141.7997\n",
      "Epoch 27/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 144.2089 - mse: 144.2089 - val_loss: 122.9268 - val_mse: 122.9268\n",
      "Epoch 28/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 124.9120 - mse: 124.9120 - val_loss: 105.4973 - val_mse: 105.4973\n",
      "Epoch 29/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 106.3626 - mse: 106.3626 - val_loss: 89.8839 - val_mse: 89.8839\n",
      "Epoch 30/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 90.7106 - mse: 90.7106 - val_loss: 75.9641 - val_mse: 75.9641\n",
      "Epoch 31/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 76.3094 - mse: 76.3094 - val_loss: 64.2191 - val_mse: 64.2191\n",
      "Epoch 32/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 64.2510 - mse: 64.2510 - val_loss: 54.7204 - val_mse: 54.7204\n",
      "Epoch 33/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 54.1944 - mse: 54.1944 - val_loss: 47.3716 - val_mse: 47.3716\n",
      "Epoch 34/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 46.3370 - mse: 46.3370 - val_loss: 41.8661 - val_mse: 41.8661\n",
      "Epoch 35/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 40.3736 - mse: 40.3736 - val_loss: 37.9294 - val_mse: 37.9294\n",
      "Epoch 36/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 35.7181 - mse: 35.7181 - val_loss: 35.1125 - val_mse: 35.1125\n",
      "Epoch 37/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 32.4421 - mse: 32.4421 - val_loss: 32.9264 - val_mse: 32.9264\n",
      "Epoch 38/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 30.0257 - mse: 30.0257 - val_loss: 31.2582 - val_mse: 31.2582\n",
      "Epoch 39/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 27.8007 - mse: 27.8007 - val_loss: 29.7983 - val_mse: 29.7983\n",
      "Epoch 40/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 26.2197 - mse: 26.2197 - val_loss: 28.3606 - val_mse: 28.3606\n",
      "Epoch 41/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 24.7216 - mse: 24.7216 - val_loss: 26.8283 - val_mse: 26.8283\n",
      "Epoch 42/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 23.2010 - mse: 23.2010 - val_loss: 25.3405 - val_mse: 25.3405\n",
      "Epoch 43/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 21.8717 - mse: 21.8717 - val_loss: 23.8272 - val_mse: 23.8272\n",
      "Epoch 44/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 20.6411 - mse: 20.6411 - val_loss: 22.4587 - val_mse: 22.4587\n",
      "Epoch 45/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 19.5102 - mse: 19.5102 - val_loss: 21.2105 - val_mse: 21.2105\n",
      "Epoch 46/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 18.5075 - mse: 18.5075 - val_loss: 20.0437 - val_mse: 20.0437\n",
      "Epoch 47/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 17.6608 - mse: 17.6608 - val_loss: 18.9791 - val_mse: 18.9791\n",
      "Epoch 48/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 16.8880 - mse: 16.8880 - val_loss: 18.0892 - val_mse: 18.0892\n",
      "Epoch 49/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 16.2376 - mse: 16.2376 - val_loss: 17.3200 - val_mse: 17.3200\n",
      "Epoch 50/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 15.6695 - mse: 15.6695 - val_loss: 16.6561 - val_mse: 16.6561\n",
      "Epoch 51/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 15.1443 - mse: 15.1443 - val_loss: 16.0833 - val_mse: 16.0833\n",
      "Epoch 52/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 14.7171 - mse: 14.7171 - val_loss: 15.5758 - val_mse: 15.5758\n",
      "Epoch 53/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 14.2711 - mse: 14.2711 - val_loss: 15.1214 - val_mse: 15.1214\n",
      "Epoch 54/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 13.9404 - mse: 13.9404 - val_loss: 14.7271 - val_mse: 14.7271\n",
      "Epoch 55/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 13.5971 - mse: 13.5971 - val_loss: 14.3468 - val_mse: 14.3468\n",
      "Epoch 56/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 13.2964 - mse: 13.2964 - val_loss: 13.9795 - val_mse: 13.9795\n",
      "Epoch 57/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 13.0314 - mse: 13.0314 - val_loss: 13.6416 - val_mse: 13.6416\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 78us/sample - loss: 12.7709 - mse: 12.7709 - val_loss: 13.3493 - val_mse: 13.3493\n",
      "Epoch 59/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 12.5596 - mse: 12.5596 - val_loss: 13.0932 - val_mse: 13.0932\n",
      "Epoch 60/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 12.3350 - mse: 12.3350 - val_loss: 12.8810 - val_mse: 12.8810\n",
      "Epoch 61/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 12.1223 - mse: 12.1223 - val_loss: 12.6700 - val_mse: 12.6700\n",
      "Epoch 62/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 11.9287 - mse: 11.9287 - val_loss: 12.4554 - val_mse: 12.4554\n",
      "Epoch 63/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 11.7625 - mse: 11.7625 - val_loss: 12.2662 - val_mse: 12.2662\n",
      "Epoch 64/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 11.5947 - mse: 11.5947 - val_loss: 12.0869 - val_mse: 12.0869\n",
      "Epoch 65/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 11.4280 - mse: 11.4280 - val_loss: 11.9067 - val_mse: 11.9067\n",
      "Epoch 66/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 11.2883 - mse: 11.2883 - val_loss: 11.7604 - val_mse: 11.7604\n",
      "Epoch 67/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 11.1360 - mse: 11.1360 - val_loss: 11.6564 - val_mse: 11.6564\n",
      "Epoch 68/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 11.0016 - mse: 11.0016 - val_loss: 11.5223 - val_mse: 11.5223\n",
      "Epoch 69/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 10.8758 - mse: 10.8758 - val_loss: 11.4045 - val_mse: 11.4045\n",
      "Epoch 70/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 10.7639 - mse: 10.7639 - val_loss: 11.2821 - val_mse: 11.2821\n",
      "Epoch 71/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 10.6505 - mse: 10.6505 - val_loss: 11.1615 - val_mse: 11.1615\n",
      "Epoch 72/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 10.5471 - mse: 10.5471 - val_loss: 11.0333 - val_mse: 11.0333\n",
      "Epoch 73/500\n",
      "294/294 [==============================] - 0s 116us/sample - loss: 10.4471 - mse: 10.4471 - val_loss: 10.9082 - val_mse: 10.9082\n",
      "Epoch 74/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 10.3479 - mse: 10.3479 - val_loss: 10.8185 - val_mse: 10.8185\n",
      "Epoch 75/500\n",
      "294/294 [==============================] - 0s 126us/sample - loss: 10.2616 - mse: 10.2616 - val_loss: 10.7091 - val_mse: 10.7091\n",
      "Epoch 76/500\n",
      "294/294 [==============================] - 0s 122us/sample - loss: 10.1738 - mse: 10.1738 - val_loss: 10.6169 - val_mse: 10.6169\n",
      "Epoch 77/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 10.0906 - mse: 10.0906 - val_loss: 10.5405 - val_mse: 10.5405\n",
      "Epoch 78/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 10.0051 - mse: 10.0051 - val_loss: 10.4716 - val_mse: 10.4716\n",
      "Epoch 79/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.9376 - mse: 9.9376 - val_loss: 10.4142 - val_mse: 10.4142\n",
      "Epoch 80/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 9.8619 - mse: 9.8619 - val_loss: 10.3017 - val_mse: 10.3017\n",
      "Epoch 81/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.7829 - mse: 9.7829 - val_loss: 10.1442 - val_mse: 10.1442\n",
      "Epoch 82/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 9.7156 - mse: 9.7156 - val_loss: 10.0209 - val_mse: 10.0209\n",
      "Epoch 83/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 9.6450 - mse: 9.6450 - val_loss: 9.9295 - val_mse: 9.9295\n",
      "Epoch 84/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.5727 - mse: 9.5727 - val_loss: 9.8815 - val_mse: 9.8815\n",
      "Epoch 85/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 9.5105 - mse: 9.5105 - val_loss: 9.8240 - val_mse: 9.8240\n",
      "Epoch 86/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 9.4445 - mse: 9.4445 - val_loss: 9.7521 - val_mse: 9.7521\n",
      "Epoch 87/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.3812 - mse: 9.3812 - val_loss: 9.6931 - val_mse: 9.6931\n",
      "Epoch 88/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 9.3224 - mse: 9.3224 - val_loss: 9.6555 - val_mse: 9.6555\n",
      "Epoch 89/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 9.2612 - mse: 9.2612 - val_loss: 9.5956 - val_mse: 9.5956\n",
      "Epoch 90/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 9.2063 - mse: 9.2063 - val_loss: 9.5129 - val_mse: 9.5129\n",
      "Epoch 91/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.1522 - mse: 9.1522 - val_loss: 9.4497 - val_mse: 9.4497\n",
      "Epoch 92/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 9.0967 - mse: 9.0967 - val_loss: 9.3613 - val_mse: 9.3613\n",
      "Epoch 93/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 9.0398 - mse: 9.0398 - val_loss: 9.2572 - val_mse: 9.2572\n",
      "Epoch 94/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 8.9903 - mse: 8.9903 - val_loss: 9.1559 - val_mse: 9.1559\n",
      "Epoch 95/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 8.9447 - mse: 8.9447 - val_loss: 9.0534 - val_mse: 9.0534\n",
      "Epoch 96/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 8.9017 - mse: 8.9017 - val_loss: 8.9822 - val_mse: 8.9822\n",
      "Epoch 97/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 8.8560 - mse: 8.8561 - val_loss: 8.9604 - val_mse: 8.9604\n",
      "Epoch 98/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 8.7998 - mse: 8.7998 - val_loss: 8.9548 - val_mse: 8.9548\n",
      "Epoch 99/500\n",
      "294/294 [==============================] - 0s 116us/sample - loss: 8.7474 - mse: 8.7474 - val_loss: 8.9707 - val_mse: 8.9707\n",
      "Epoch 100/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 8.7043 - mse: 8.7043 - val_loss: 8.9765 - val_mse: 8.9765\n",
      "Epoch 101/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 8.6506 - mse: 8.6506 - val_loss: 8.9448 - val_mse: 8.9448\n",
      "Epoch 102/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.6114 - mse: 8.6114 - val_loss: 8.9276 - val_mse: 8.9276\n",
      "Epoch 103/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.5702 - mse: 8.5702 - val_loss: 8.8781 - val_mse: 8.8781\n",
      "Epoch 104/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 8.5331 - mse: 8.5331 - val_loss: 8.7717 - val_mse: 8.7717\n",
      "Epoch 105/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 8.4842 - mse: 8.4842 - val_loss: 8.6894 - val_mse: 8.6894\n",
      "Epoch 106/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 8.4379 - mse: 8.4379 - val_loss: 8.6565 - val_mse: 8.6565\n",
      "Epoch 107/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 8.3970 - mse: 8.3970 - val_loss: 8.6135 - val_mse: 8.6135\n",
      "Epoch 108/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.3476 - mse: 8.3476 - val_loss: 8.5406 - val_mse: 8.5406\n",
      "Epoch 109/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 8.3118 - mse: 8.3118 - val_loss: 8.4683 - val_mse: 8.4683\n",
      "Epoch 110/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.2643 - mse: 8.2643 - val_loss: 8.4307 - val_mse: 8.4307\n",
      "Epoch 111/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.2185 - mse: 8.2185 - val_loss: 8.3880 - val_mse: 8.3880\n",
      "Epoch 112/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.1797 - mse: 8.1797 - val_loss: 8.3489 - val_mse: 8.3489\n",
      "Epoch 113/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.1402 - mse: 8.1402 - val_loss: 8.3305 - val_mse: 8.3305\n",
      "Epoch 114/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 8.1015 - mse: 8.1015 - val_loss: 8.3177 - val_mse: 8.3177\n",
      "Epoch 115/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.0681 - mse: 8.0681 - val_loss: 8.2856 - val_mse: 8.2856\n",
      "Epoch 116/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 8.0336 - mse: 8.0336 - val_loss: 8.2101 - val_mse: 8.2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.9956 - mse: 7.9956 - val_loss: 8.1447 - val_mse: 8.1447\n",
      "Epoch 118/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.9595 - mse: 7.9595 - val_loss: 8.0980 - val_mse: 8.0980\n",
      "Epoch 119/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.9343 - mse: 7.9343 - val_loss: 8.0869 - val_mse: 8.0869\n",
      "Epoch 120/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.8975 - mse: 7.8975 - val_loss: 8.1206 - val_mse: 8.1206\n",
      "Epoch 121/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.8597 - mse: 7.8597 - val_loss: 8.1605 - val_mse: 8.1605\n",
      "Epoch 122/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.8299 - mse: 7.8299 - val_loss: 8.1928 - val_mse: 8.1928\n",
      "Epoch 123/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 7.8020 - mse: 7.8020 - val_loss: 8.2289 - val_mse: 8.2289\n",
      "Epoch 124/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 7.7763 - mse: 7.7763 - val_loss: 8.2522 - val_mse: 8.2522\n",
      "Epoch 125/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.7516 - mse: 7.7516 - val_loss: 8.2315 - val_mse: 8.2315\n",
      "Epoch 126/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.7208 - mse: 7.7208 - val_loss: 8.1776 - val_mse: 8.1776\n",
      "Epoch 127/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.6896 - mse: 7.6896 - val_loss: 8.1222 - val_mse: 8.1222\n",
      "Epoch 128/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.6507 - mse: 7.6507 - val_loss: 8.0187 - val_mse: 8.0187\n",
      "Epoch 129/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.6153 - mse: 7.6153 - val_loss: 7.8829 - val_mse: 7.8829\n",
      "Epoch 130/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.5802 - mse: 7.5802 - val_loss: 7.7943 - val_mse: 7.7943\n",
      "Epoch 131/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.5620 - mse: 7.5620 - val_loss: 7.7411 - val_mse: 7.7411\n",
      "Epoch 132/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.5328 - mse: 7.5328 - val_loss: 7.7351 - val_mse: 7.7351\n",
      "Epoch 133/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.5066 - mse: 7.5066 - val_loss: 7.7462 - val_mse: 7.7462\n",
      "Epoch 134/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.4776 - mse: 7.4776 - val_loss: 7.7487 - val_mse: 7.7487\n",
      "Epoch 135/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.4514 - mse: 7.4514 - val_loss: 7.7744 - val_mse: 7.7744\n",
      "Epoch 136/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.4143 - mse: 7.4143 - val_loss: 7.8314 - val_mse: 7.8314\n",
      "Epoch 137/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.4082 - mse: 7.4082 - val_loss: 7.9172 - val_mse: 7.9172\n",
      "Epoch 138/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 7.3740 - mse: 7.3740 - val_loss: 7.9028 - val_mse: 7.9028\n",
      "Epoch 139/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.3490 - mse: 7.3490 - val_loss: 7.8520 - val_mse: 7.8520\n",
      "Epoch 140/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.3232 - mse: 7.3232 - val_loss: 7.7789 - val_mse: 7.7789\n",
      "Epoch 141/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.2969 - mse: 7.2969 - val_loss: 7.7182 - val_mse: 7.7182\n",
      "Epoch 142/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 7.2726 - mse: 7.2726 - val_loss: 7.6827 - val_mse: 7.6827\n",
      "Epoch 143/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.2504 - mse: 7.2504 - val_loss: 7.6258 - val_mse: 7.6258\n",
      "Epoch 144/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 7.2248 - mse: 7.2248 - val_loss: 7.5916 - val_mse: 7.5916\n",
      "Epoch 145/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 7.1995 - mse: 7.1995 - val_loss: 7.5509 - val_mse: 7.5509\n",
      "Epoch 146/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.1785 - mse: 7.1785 - val_loss: 7.5175 - val_mse: 7.5175\n",
      "Epoch 147/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 7.1556 - mse: 7.1556 - val_loss: 7.5127 - val_mse: 7.5127\n",
      "Epoch 148/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 7.1350 - mse: 7.1350 - val_loss: 7.5279 - val_mse: 7.5279\n",
      "Epoch 149/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 7.1159 - mse: 7.1159 - val_loss: 7.5347 - val_mse: 7.5347\n",
      "Epoch 150/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.0955 - mse: 7.0955 - val_loss: 7.4911 - val_mse: 7.4911\n",
      "Epoch 151/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.0729 - mse: 7.0729 - val_loss: 7.4674 - val_mse: 7.4674\n",
      "Epoch 152/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.0472 - mse: 7.0472 - val_loss: 7.4337 - val_mse: 7.4337\n",
      "Epoch 153/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.0255 - mse: 7.0255 - val_loss: 7.3989 - val_mse: 7.3989\n",
      "Epoch 154/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 7.0107 - mse: 7.0107 - val_loss: 7.3719 - val_mse: 7.3719\n",
      "Epoch 155/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.9940 - mse: 6.9940 - val_loss: 7.3620 - val_mse: 7.3620\n",
      "Epoch 156/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.9816 - mse: 6.9816 - val_loss: 7.3796 - val_mse: 7.3796\n",
      "Epoch 157/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.9550 - mse: 6.9550 - val_loss: 7.3760 - val_mse: 7.3760\n",
      "Epoch 158/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.9292 - mse: 6.9292 - val_loss: 7.3860 - val_mse: 7.3860\n",
      "Epoch 159/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.9123 - mse: 6.9123 - val_loss: 7.3882 - val_mse: 7.3882\n",
      "Epoch 160/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.8961 - mse: 6.8961 - val_loss: 7.3629 - val_mse: 7.3629\n",
      "Epoch 161/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.8747 - mse: 6.8747 - val_loss: 7.2892 - val_mse: 7.2892\n",
      "Epoch 162/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.8616 - mse: 6.8616 - val_loss: 7.2557 - val_mse: 7.2557\n",
      "Epoch 163/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.8476 - mse: 6.8476 - val_loss: 7.2342 - val_mse: 7.2342\n",
      "Epoch 164/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.8295 - mse: 6.8295 - val_loss: 7.2292 - val_mse: 7.2292\n",
      "Epoch 165/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.8209 - mse: 6.8209 - val_loss: 7.2232 - val_mse: 7.2232\n",
      "Epoch 166/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.8064 - mse: 6.8064 - val_loss: 7.1888 - val_mse: 7.1888\n",
      "Epoch 167/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 6.7858 - mse: 6.7858 - val_loss: 7.2135 - val_mse: 7.2135\n",
      "Epoch 168/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.7773 - mse: 6.7773 - val_loss: 7.2416 - val_mse: 7.2416\n",
      "Epoch 169/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.7598 - mse: 6.7598 - val_loss: 7.2818 - val_mse: 7.2818\n",
      "Epoch 170/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.7467 - mse: 6.7467 - val_loss: 7.3115 - val_mse: 7.3115\n",
      "Epoch 171/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.7311 - mse: 6.7311 - val_loss: 7.3248 - val_mse: 7.3248\n",
      "Epoch 172/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.7141 - mse: 6.7141 - val_loss: 7.3060 - val_mse: 7.3060\n",
      "Epoch 173/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.6960 - mse: 6.6960 - val_loss: 7.2918 - val_mse: 7.2918\n",
      "Epoch 174/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.6762 - mse: 6.6762 - val_loss: 7.2870 - val_mse: 7.2870\n",
      "Epoch 175/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.6616 - mse: 6.6616 - val_loss: 7.2491 - val_mse: 7.2491\n",
      "Epoch 176/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 78us/sample - loss: 6.6492 - mse: 6.6492 - val_loss: 7.2188 - val_mse: 7.2188\n",
      "Epoch 177/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.6380 - mse: 6.6380 - val_loss: 7.2183 - val_mse: 7.2183\n",
      "Epoch 178/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.6244 - mse: 6.6244 - val_loss: 7.2011 - val_mse: 7.2011\n",
      "Epoch 179/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.6129 - mse: 6.6129 - val_loss: 7.2016 - val_mse: 7.2016\n",
      "Epoch 180/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.6009 - mse: 6.6009 - val_loss: 7.2068 - val_mse: 7.2068\n",
      "Epoch 181/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.5903 - mse: 6.5903 - val_loss: 7.1883 - val_mse: 7.1883\n",
      "Epoch 182/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.5753 - mse: 6.5753 - val_loss: 7.1623 - val_mse: 7.1623\n",
      "Epoch 183/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.5611 - mse: 6.5611 - val_loss: 7.1512 - val_mse: 7.1512\n",
      "Epoch 184/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.5487 - mse: 6.5487 - val_loss: 7.1391 - val_mse: 7.1391\n",
      "Epoch 185/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.5363 - mse: 6.5363 - val_loss: 7.1383 - val_mse: 7.1383\n",
      "Epoch 186/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.5222 - mse: 6.5222 - val_loss: 7.1135 - val_mse: 7.1135\n",
      "Epoch 187/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.5149 - mse: 6.5149 - val_loss: 7.0841 - val_mse: 7.0841\n",
      "Epoch 188/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.5042 - mse: 6.5042 - val_loss: 7.0288 - val_mse: 7.0288\n",
      "Epoch 189/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.4935 - mse: 6.4935 - val_loss: 7.0358 - val_mse: 7.0358\n",
      "Epoch 190/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.4835 - mse: 6.4835 - val_loss: 7.0419 - val_mse: 7.0419\n",
      "Epoch 191/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.4716 - mse: 6.4716 - val_loss: 7.0622 - val_mse: 7.0622\n",
      "Epoch 192/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.4592 - mse: 6.4592 - val_loss: 7.0921 - val_mse: 7.0921\n",
      "Epoch 193/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.4575 - mse: 6.4575 - val_loss: 7.1120 - val_mse: 7.1120\n",
      "Epoch 194/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.4382 - mse: 6.4382 - val_loss: 7.0877 - val_mse: 7.0877\n",
      "Epoch 195/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.4313 - mse: 6.4313 - val_loss: 7.0638 - val_mse: 7.0638\n",
      "Epoch 196/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.4229 - mse: 6.4229 - val_loss: 7.0703 - val_mse: 7.0703\n",
      "Epoch 197/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.4140 - mse: 6.4140 - val_loss: 7.1043 - val_mse: 7.1043\n",
      "Epoch 198/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.4018 - mse: 6.4018 - val_loss: 7.1379 - val_mse: 7.1379\n",
      "Epoch 199/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.3814 - mse: 6.3814 - val_loss: 7.2268 - val_mse: 7.2268\n",
      "Epoch 200/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 6.3973 - mse: 6.3973 - val_loss: 7.2947 - val_mse: 7.2947\n",
      "Epoch 201/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.3882 - mse: 6.3882 - val_loss: 7.3097 - val_mse: 7.3097\n",
      "Epoch 202/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 6.3824 - mse: 6.3824 - val_loss: 7.2954 - val_mse: 7.2954\n",
      "Epoch 203/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.3720 - mse: 6.3720 - val_loss: 7.2681 - val_mse: 7.2681\n",
      "Epoch 204/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.3557 - mse: 6.3557 - val_loss: 7.2122 - val_mse: 7.2122\n",
      "Epoch 205/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.3413 - mse: 6.3413 - val_loss: 7.1390 - val_mse: 7.1390\n",
      "Epoch 206/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.3272 - mse: 6.3272 - val_loss: 7.0707 - val_mse: 7.0707\n",
      "Epoch 207/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.3211 - mse: 6.3211 - val_loss: 7.0221 - val_mse: 7.0221\n",
      "Epoch 208/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.3135 - mse: 6.3135 - val_loss: 6.9980 - val_mse: 6.9980\n",
      "Epoch 209/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.3087 - mse: 6.3087 - val_loss: 6.9811 - val_mse: 6.9811\n",
      "Epoch 210/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.2988 - mse: 6.2988 - val_loss: 7.0107 - val_mse: 7.0107\n",
      "Epoch 211/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.2887 - mse: 6.2887 - val_loss: 7.0345 - val_mse: 7.0345\n",
      "Epoch 212/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.2809 - mse: 6.2809 - val_loss: 7.0292 - val_mse: 7.0292\n",
      "Epoch 213/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.2721 - mse: 6.2721 - val_loss: 7.0220 - val_mse: 7.0220\n",
      "Epoch 214/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2666 - mse: 6.2666 - val_loss: 7.0334 - val_mse: 7.0334\n",
      "Epoch 215/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2554 - mse: 6.2554 - val_loss: 7.1115 - val_mse: 7.1115\n",
      "Epoch 216/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2493 - mse: 6.2493 - val_loss: 7.1734 - val_mse: 7.1734\n",
      "Epoch 217/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.2459 - mse: 6.2459 - val_loss: 7.1899 - val_mse: 7.1899\n",
      "Epoch 218/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2389 - mse: 6.2389 - val_loss: 7.1950 - val_mse: 7.1950\n",
      "Epoch 219/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.2335 - mse: 6.2335 - val_loss: 7.1799 - val_mse: 7.1799\n",
      "Epoch 220/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2268 - mse: 6.2268 - val_loss: 7.1368 - val_mse: 7.1368\n",
      "Epoch 221/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.2119 - mse: 6.2119 - val_loss: 7.0918 - val_mse: 7.0918\n",
      "Epoch 222/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.1999 - mse: 6.1999 - val_loss: 7.0552 - val_mse: 7.0552\n",
      "Epoch 223/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.1914 - mse: 6.1914 - val_loss: 7.0182 - val_mse: 7.0182\n",
      "Epoch 224/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.1856 - mse: 6.1856 - val_loss: 6.9971 - val_mse: 6.9971\n",
      "Epoch 225/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.1815 - mse: 6.1815 - val_loss: 7.0108 - val_mse: 7.0108\n",
      "Epoch 226/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.1777 - mse: 6.1777 - val_loss: 7.0224 - val_mse: 7.0224\n",
      "Epoch 227/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.1662 - mse: 6.1662 - val_loss: 7.0801 - val_mse: 7.0801\n",
      "Epoch 228/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.1599 - mse: 6.1599 - val_loss: 7.1168 - val_mse: 7.1168\n",
      "Epoch 229/500\n",
      "294/294 [==============================] - 0s 92us/sample - loss: 6.1538 - mse: 6.1538 - val_loss: 7.1512 - val_mse: 7.1512\n",
      "Epoch 230/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 6.1482 - mse: 6.1482 - val_loss: 7.1548 - val_mse: 7.1548\n",
      "Epoch 231/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.1394 - mse: 6.1394 - val_loss: 7.1314 - val_mse: 7.1314\n",
      "Epoch 232/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.1302 - mse: 6.1302 - val_loss: 7.1386 - val_mse: 7.1386\n",
      "Epoch 233/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.1206 - mse: 6.1206 - val_loss: 7.2083 - val_mse: 7.2083\n",
      "Epoch 234/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.1170 - mse: 6.1170 - val_loss: 7.2777 - val_mse: 7.2777\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 78us/sample - loss: 6.1255 - mse: 6.1255 - val_loss: 7.3335 - val_mse: 7.3335\n",
      "Epoch 236/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.1211 - mse: 6.1211 - val_loss: 7.3309 - val_mse: 7.3309\n",
      "Epoch 237/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.1065 - mse: 6.1065 - val_loss: 7.2925 - val_mse: 7.2925\n",
      "Epoch 238/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.0935 - mse: 6.0935 - val_loss: 7.2428 - val_mse: 7.2428\n",
      "Epoch 239/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0829 - mse: 6.0829 - val_loss: 7.1952 - val_mse: 7.1952\n",
      "Epoch 240/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0760 - mse: 6.0760 - val_loss: 7.1525 - val_mse: 7.1525\n",
      "Epoch 241/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.0705 - mse: 6.0705 - val_loss: 7.1406 - val_mse: 7.1406\n",
      "Epoch 242/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0673 - mse: 6.0673 - val_loss: 7.1210 - val_mse: 7.1210\n",
      "Epoch 243/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0684 - mse: 6.0684 - val_loss: 7.1042 - val_mse: 7.1042\n",
      "Epoch 244/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.0596 - mse: 6.0596 - val_loss: 7.0611 - val_mse: 7.0611\n",
      "Epoch 245/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0516 - mse: 6.0516 - val_loss: 7.0537 - val_mse: 7.0537\n",
      "Epoch 246/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.0475 - mse: 6.0475 - val_loss: 7.0656 - val_mse: 7.0656\n",
      "Epoch 247/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0352 - mse: 6.0352 - val_loss: 7.0983 - val_mse: 7.0983\n",
      "Epoch 248/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0295 - mse: 6.0295 - val_loss: 7.1254 - val_mse: 7.1254\n",
      "Epoch 249/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 6.0337 - mse: 6.0337 - val_loss: 7.1866 - val_mse: 7.1866\n",
      "Epoch 250/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 6.0389 - mse: 6.0389 - val_loss: 7.2064 - val_mse: 7.2064\n",
      "Epoch 251/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 6.0308 - mse: 6.0308 - val_loss: 7.1357 - val_mse: 7.1357\n",
      "Epoch 252/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.0155 - mse: 6.0155 - val_loss: 7.1036 - val_mse: 7.1036\n",
      "Epoch 253/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0119 - mse: 6.0119 - val_loss: 7.0553 - val_mse: 7.0553\n",
      "Epoch 254/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0137 - mse: 6.0137 - val_loss: 7.0187 - val_mse: 7.0187\n",
      "Epoch 255/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 6.0057 - mse: 6.0057 - val_loss: 7.0238 - val_mse: 7.0238\n",
      "Epoch 256/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.9974 - mse: 5.9974 - val_loss: 7.0748 - val_mse: 7.0748\n",
      "Epoch 257/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 6.0038 - mse: 6.0038 - val_loss: 7.0903 - val_mse: 7.0903\n",
      "Epoch 258/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.9872 - mse: 5.9872 - val_loss: 7.0325 - val_mse: 7.0325\n",
      "Epoch 259/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 5.9842 - mse: 5.9842 - val_loss: 6.9846 - val_mse: 6.9846\n",
      "Epoch 260/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.9789 - mse: 5.9789 - val_loss: 6.9647 - val_mse: 6.9647\n",
      "Epoch 261/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9706 - mse: 5.9706 - val_loss: 6.9911 - val_mse: 6.9911\n",
      "Epoch 262/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.9712 - mse: 5.9712 - val_loss: 7.0482 - val_mse: 7.0482\n",
      "Epoch 263/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9550 - mse: 5.9550 - val_loss: 7.0447 - val_mse: 7.0447\n",
      "Epoch 264/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9518 - mse: 5.9518 - val_loss: 7.0320 - val_mse: 7.0320\n",
      "Epoch 265/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9516 - mse: 5.9516 - val_loss: 7.0129 - val_mse: 7.0129\n",
      "Epoch 266/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.9506 - mse: 5.9506 - val_loss: 6.9892 - val_mse: 6.9892\n",
      "Epoch 267/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.9419 - mse: 5.9419 - val_loss: 6.9730 - val_mse: 6.9730\n",
      "Epoch 268/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9455 - mse: 5.9455 - val_loss: 6.9456 - val_mse: 6.9456\n",
      "Epoch 269/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.9391 - mse: 5.9391 - val_loss: 6.9604 - val_mse: 6.9604\n",
      "Epoch 270/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.9333 - mse: 5.9333 - val_loss: 6.9860 - val_mse: 6.9860\n",
      "Epoch 271/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.9241 - mse: 5.9241 - val_loss: 7.0412 - val_mse: 7.0412\n",
      "Epoch 272/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9331 - mse: 5.9331 - val_loss: 7.1093 - val_mse: 7.1093\n",
      "Epoch 273/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9190 - mse: 5.9190 - val_loss: 7.1318 - val_mse: 7.1318\n",
      "Epoch 274/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.9120 - mse: 5.9120 - val_loss: 7.1275 - val_mse: 7.1275\n",
      "Epoch 275/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.9049 - mse: 5.9049 - val_loss: 7.1467 - val_mse: 7.1467\n",
      "Epoch 276/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.9078 - mse: 5.9078 - val_loss: 7.1206 - val_mse: 7.1206\n",
      "Epoch 277/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.8945 - mse: 5.8945 - val_loss: 7.0625 - val_mse: 7.0625\n",
      "Epoch 278/500\n",
      "294/294 [==============================] - 0s 92us/sample - loss: 5.8909 - mse: 5.8909 - val_loss: 6.9945 - val_mse: 6.9945\n",
      "Epoch 279/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8908 - mse: 5.8908 - val_loss: 6.9291 - val_mse: 6.9291\n",
      "Epoch 280/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8913 - mse: 5.8913 - val_loss: 6.8739 - val_mse: 6.8739\n",
      "Epoch 281/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8855 - mse: 5.8855 - val_loss: 6.8632 - val_mse: 6.8632\n",
      "Epoch 282/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8859 - mse: 5.8859 - val_loss: 6.8846 - val_mse: 6.8846\n",
      "Epoch 283/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8774 - mse: 5.8774 - val_loss: 6.9094 - val_mse: 6.9094\n",
      "Epoch 284/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.8694 - mse: 5.8694 - val_loss: 6.9202 - val_mse: 6.9202\n",
      "Epoch 285/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8610 - mse: 5.8610 - val_loss: 6.9104 - val_mse: 6.9104\n",
      "Epoch 286/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.8542 - mse: 5.8542 - val_loss: 6.9041 - val_mse: 6.9041\n",
      "Epoch 287/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 5.8531 - mse: 5.8531 - val_loss: 6.9062 - val_mse: 6.9062\n",
      "Epoch 288/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8505 - mse: 5.8505 - val_loss: 6.9235 - val_mse: 6.9235\n",
      "Epoch 289/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8431 - mse: 5.8431 - val_loss: 6.9745 - val_mse: 6.9745\n",
      "Epoch 290/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.8371 - mse: 5.8371 - val_loss: 7.0174 - val_mse: 7.0174\n",
      "Epoch 291/500\n",
      "294/294 [==============================] - 0s 92us/sample - loss: 5.8308 - mse: 5.8308 - val_loss: 7.0255 - val_mse: 7.0255\n",
      "Epoch 292/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8296 - mse: 5.8296 - val_loss: 7.0159 - val_mse: 7.0159\n",
      "Epoch 293/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8236 - mse: 5.8236 - val_loss: 7.0503 - val_mse: 7.0503\n",
      "Epoch 294/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8329 - mse: 5.8329 - val_loss: 7.1141 - val_mse: 7.1141\n",
      "Epoch 295/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.8235 - mse: 5.8235 - val_loss: 7.1226 - val_mse: 7.1226\n",
      "Epoch 296/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.8176 - mse: 5.8176 - val_loss: 7.0987 - val_mse: 7.0987\n",
      "Epoch 297/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.8141 - mse: 5.8141 - val_loss: 7.0507 - val_mse: 7.0507\n",
      "Epoch 298/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.8120 - mse: 5.8120 - val_loss: 7.0006 - val_mse: 7.0006\n",
      "Epoch 299/500\n",
      "294/294 [==============================] - 0s 95us/sample - loss: 5.8167 - mse: 5.8167 - val_loss: 6.9828 - val_mse: 6.9828\n",
      "Epoch 300/500\n",
      "294/294 [==============================] - 0s 126us/sample - loss: 5.8321 - mse: 5.8321 - val_loss: 6.9661 - val_mse: 6.9661\n",
      "Epoch 301/500\n",
      "294/294 [==============================] - 0s 116us/sample - loss: 5.8327 - mse: 5.8327 - val_loss: 6.9844 - val_mse: 6.9844\n",
      "Epoch 302/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.8123 - mse: 5.8123 - val_loss: 7.0130 - val_mse: 7.0130\n",
      "Epoch 303/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 5.7908 - mse: 5.7908 - val_loss: 7.0963 - val_mse: 7.0963\n",
      "Epoch 304/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 5.7843 - mse: 5.7843 - val_loss: 7.1838 - val_mse: 7.1838\n",
      "Epoch 305/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 5.7776 - mse: 5.7776 - val_loss: 7.2322 - val_mse: 7.2322\n",
      "Epoch 306/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 5.7882 - mse: 5.7882 - val_loss: 7.2881 - val_mse: 7.2881\n",
      "Epoch 307/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.7984 - mse: 5.7984 - val_loss: 7.2548 - val_mse: 7.2548\n",
      "Epoch 308/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 5.7866 - mse: 5.7866 - val_loss: 7.1739 - val_mse: 7.1739\n",
      "Epoch 309/500\n",
      "294/294 [==============================] - 0s 112us/sample - loss: 5.7732 - mse: 5.7732 - val_loss: 7.1242 - val_mse: 7.1242\n",
      "Epoch 310/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.7636 - mse: 5.7636 - val_loss: 7.0914 - val_mse: 7.0914\n",
      "Epoch 311/500\n",
      "294/294 [==============================] - 0s 116us/sample - loss: 5.7560 - mse: 5.7560 - val_loss: 7.0824 - val_mse: 7.0824\n",
      "Epoch 312/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.7505 - mse: 5.7505 - val_loss: 7.0853 - val_mse: 7.0853\n",
      "Epoch 313/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 5.7489 - mse: 5.7489 - val_loss: 7.0957 - val_mse: 7.0957\n",
      "Epoch 314/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.7432 - mse: 5.7432 - val_loss: 7.0908 - val_mse: 7.0908\n",
      "Epoch 315/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 5.7359 - mse: 5.7359 - val_loss: 7.0529 - val_mse: 7.0529\n",
      "Epoch 316/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.7382 - mse: 5.7382 - val_loss: 7.0080 - val_mse: 7.0080\n",
      "Epoch 317/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 5.7346 - mse: 5.7346 - val_loss: 7.0354 - val_mse: 7.0354\n",
      "Epoch 318/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 5.7288 - mse: 5.7288 - val_loss: 7.0613 - val_mse: 7.0613\n",
      "Epoch 319/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.7217 - mse: 5.7217 - val_loss: 7.1008 - val_mse: 7.1008\n",
      "Epoch 320/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.7336 - mse: 5.7336 - val_loss: 7.1363 - val_mse: 7.1363\n",
      "Epoch 321/500\n",
      "294/294 [==============================] - 0s 99us/sample - loss: 5.7191 - mse: 5.7191 - val_loss: 7.1096 - val_mse: 7.1096\n",
      "Epoch 322/500\n",
      "294/294 [==============================] - 0s 105us/sample - loss: 5.7160 - mse: 5.7160 - val_loss: 7.1008 - val_mse: 7.1008\n",
      "Epoch 323/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.7104 - mse: 5.7104 - val_loss: 7.0834 - val_mse: 7.0834\n",
      "Epoch 324/500\n",
      "294/294 [==============================] - 0s 116us/sample - loss: 5.7009 - mse: 5.7009 - val_loss: 7.1050 - val_mse: 7.1050\n",
      "Epoch 325/500\n",
      "294/294 [==============================] - 0s 109us/sample - loss: 5.6976 - mse: 5.6976 - val_loss: 7.1465 - val_mse: 7.1465\n",
      "Epoch 326/500\n",
      "294/294 [==============================] - 0s 119us/sample - loss: 5.6991 - mse: 5.6991 - val_loss: 7.1913 - val_mse: 7.1913\n",
      "Epoch 327/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.7008 - mse: 5.7008 - val_loss: 7.2663 - val_mse: 7.2663\n",
      "Epoch 328/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.7014 - mse: 5.7014 - val_loss: 7.2993 - val_mse: 7.2993\n",
      "Epoch 329/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.7057 - mse: 5.7057 - val_loss: 7.3030 - val_mse: 7.3030\n",
      "Epoch 330/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.7006 - mse: 5.7006 - val_loss: 7.2608 - val_mse: 7.2608\n",
      "Epoch 331/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.6898 - mse: 5.6898 - val_loss: 7.2072 - val_mse: 7.2072\n",
      "Epoch 332/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6753 - mse: 5.6753 - val_loss: 7.0816 - val_mse: 7.0816\n",
      "Epoch 333/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6810 - mse: 5.6810 - val_loss: 7.0013 - val_mse: 7.0013\n",
      "Epoch 334/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6911 - mse: 5.6911 - val_loss: 6.9998 - val_mse: 6.9998\n",
      "Epoch 335/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6818 - mse: 5.6818 - val_loss: 7.0563 - val_mse: 7.0563\n",
      "Epoch 336/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6698 - mse: 5.6698 - val_loss: 7.1369 - val_mse: 7.1369\n",
      "Epoch 337/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6689 - mse: 5.6689 - val_loss: 7.2032 - val_mse: 7.2032\n",
      "Epoch 338/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6615 - mse: 5.6615 - val_loss: 7.2001 - val_mse: 7.2001\n",
      "Epoch 339/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6615 - mse: 5.6615 - val_loss: 7.2073 - val_mse: 7.2073\n",
      "Epoch 340/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6671 - mse: 5.6671 - val_loss: 7.1999 - val_mse: 7.1999\n",
      "Epoch 341/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.6537 - mse: 5.6537 - val_loss: 7.2734 - val_mse: 7.2734\n",
      "Epoch 342/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6532 - mse: 5.6532 - val_loss: 7.3091 - val_mse: 7.3091\n",
      "Epoch 343/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.6547 - mse: 5.6547 - val_loss: 7.3290 - val_mse: 7.3290\n",
      "Epoch 344/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6616 - mse: 5.6616 - val_loss: 7.3475 - val_mse: 7.3475\n",
      "Epoch 345/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6683 - mse: 5.6683 - val_loss: 7.3772 - val_mse: 7.3772\n",
      "Epoch 346/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6536 - mse: 5.6536 - val_loss: 7.3066 - val_mse: 7.3066\n",
      "Epoch 347/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.6345 - mse: 5.6345 - val_loss: 7.2180 - val_mse: 7.2180\n",
      "Epoch 348/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6260 - mse: 5.6260 - val_loss: 7.1620 - val_mse: 7.1620\n",
      "Epoch 349/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6146 - mse: 5.6146 - val_loss: 7.0740 - val_mse: 7.0740\n",
      "Epoch 350/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6231 - mse: 5.6231 - val_loss: 6.9499 - val_mse: 6.9499\n",
      "Epoch 351/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.6374 - mse: 5.6374 - val_loss: 6.8820 - val_mse: 6.8820\n",
      "Epoch 352/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6331 - mse: 5.6331 - val_loss: 6.8920 - val_mse: 6.8920\n",
      "Epoch 353/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6295 - mse: 5.6295 - val_loss: 6.9066 - val_mse: 6.9066\n",
      "Epoch 354/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6188 - mse: 5.6188 - val_loss: 6.9354 - val_mse: 6.9354\n",
      "Epoch 355/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6147 - mse: 5.6147 - val_loss: 7.0189 - val_mse: 7.0189\n",
      "Epoch 356/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.6038 - mse: 5.6038 - val_loss: 7.0486 - val_mse: 7.0486\n",
      "Epoch 357/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.6039 - mse: 5.6039 - val_loss: 7.0247 - val_mse: 7.0247\n",
      "Epoch 358/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6051 - mse: 5.6051 - val_loss: 7.0036 - val_mse: 7.0036\n",
      "Epoch 359/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.6020 - mse: 5.6020 - val_loss: 6.9320 - val_mse: 6.9320\n",
      "Epoch 360/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.6010 - mse: 5.6010 - val_loss: 6.8845 - val_mse: 6.8845\n",
      "Epoch 361/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.5987 - mse: 5.5987 - val_loss: 6.9050 - val_mse: 6.9050\n",
      "Epoch 362/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5947 - mse: 5.5947 - val_loss: 6.9498 - val_mse: 6.9498\n",
      "Epoch 363/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5888 - mse: 5.5888 - val_loss: 7.0474 - val_mse: 7.0474\n",
      "Epoch 364/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5717 - mse: 5.5717 - val_loss: 7.0966 - val_mse: 7.0966\n",
      "Epoch 365/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5809 - mse: 5.5809 - val_loss: 7.1495 - val_mse: 7.1495\n",
      "Epoch 366/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5940 - mse: 5.5940 - val_loss: 7.2129 - val_mse: 7.2129\n",
      "Epoch 367/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5886 - mse: 5.5886 - val_loss: 7.2908 - val_mse: 7.2908\n",
      "Epoch 368/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5930 - mse: 5.5930 - val_loss: 7.3524 - val_mse: 7.3524\n",
      "Epoch 369/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5927 - mse: 5.5927 - val_loss: 7.3490 - val_mse: 7.3490\n",
      "Epoch 370/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5867 - mse: 5.5867 - val_loss: 7.2957 - val_mse: 7.2957\n",
      "Epoch 371/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5655 - mse: 5.5655 - val_loss: 7.2244 - val_mse: 7.2244\n",
      "Epoch 372/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5570 - mse: 5.5570 - val_loss: 7.1878 - val_mse: 7.1878\n",
      "Epoch 373/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5568 - mse: 5.5568 - val_loss: 7.1875 - val_mse: 7.1875\n",
      "Epoch 374/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5528 - mse: 5.5528 - val_loss: 7.2311 - val_mse: 7.2311\n",
      "Epoch 375/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.5484 - mse: 5.5484 - val_loss: 7.2794 - val_mse: 7.2794\n",
      "Epoch 376/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5651 - mse: 5.5651 - val_loss: 7.3295 - val_mse: 7.3295\n",
      "Epoch 377/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.5579 - mse: 5.5579 - val_loss: 7.2264 - val_mse: 7.2264\n",
      "Epoch 378/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5431 - mse: 5.5431 - val_loss: 7.1675 - val_mse: 7.1675\n",
      "Epoch 379/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5370 - mse: 5.5370 - val_loss: 7.1587 - val_mse: 7.1587\n",
      "Epoch 380/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5370 - mse: 5.5370 - val_loss: 7.1623 - val_mse: 7.1623\n",
      "Epoch 381/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5282 - mse: 5.5282 - val_loss: 7.1271 - val_mse: 7.1271\n",
      "Epoch 382/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5321 - mse: 5.5321 - val_loss: 7.0640 - val_mse: 7.0640\n",
      "Epoch 383/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5427 - mse: 5.5427 - val_loss: 7.0168 - val_mse: 7.0168\n",
      "Epoch 384/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.5508 - mse: 5.5508 - val_loss: 6.9807 - val_mse: 6.9807\n",
      "Epoch 385/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5331 - mse: 5.5331 - val_loss: 7.0362 - val_mse: 7.0362\n",
      "Epoch 386/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5109 - mse: 5.5109 - val_loss: 7.1098 - val_mse: 7.1098\n",
      "Epoch 387/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.5096 - mse: 5.5096 - val_loss: 7.2406 - val_mse: 7.2406\n",
      "Epoch 388/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.5250 - mse: 5.5250 - val_loss: 7.3953 - val_mse: 7.3953\n",
      "Epoch 389/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5593 - mse: 5.5593 - val_loss: 7.5331 - val_mse: 7.5331\n",
      "Epoch 390/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5894 - mse: 5.5894 - val_loss: 7.5925 - val_mse: 7.5925\n",
      "Epoch 391/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5924 - mse: 5.5924 - val_loss: 7.5102 - val_mse: 7.5102\n",
      "Epoch 392/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5527 - mse: 5.5527 - val_loss: 7.3939 - val_mse: 7.3939\n",
      "Epoch 393/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5139 - mse: 5.5139 - val_loss: 7.3174 - val_mse: 7.3174\n",
      "Epoch 394/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.5051 - mse: 5.5051 - val_loss: 7.2592 - val_mse: 7.2592\n",
      "Epoch 395/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5008 - mse: 5.5008 - val_loss: 7.2329 - val_mse: 7.2329\n",
      "Epoch 396/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5100 - mse: 5.5100 - val_loss: 7.1833 - val_mse: 7.1833\n",
      "Epoch 397/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5144 - mse: 5.5144 - val_loss: 7.1396 - val_mse: 7.1396\n",
      "Epoch 398/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5188 - mse: 5.5188 - val_loss: 7.1507 - val_mse: 7.1507\n",
      "Epoch 399/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.5132 - mse: 5.5132 - val_loss: 7.2058 - val_mse: 7.2058\n",
      "Epoch 400/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4937 - mse: 5.4937 - val_loss: 7.2848 - val_mse: 7.2848\n",
      "Epoch 401/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4938 - mse: 5.4938 - val_loss: 7.3408 - val_mse: 7.3408\n",
      "Epoch 402/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.4885 - mse: 5.4885 - val_loss: 7.3828 - val_mse: 7.3828\n",
      "Epoch 403/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4890 - mse: 5.4890 - val_loss: 7.3511 - val_mse: 7.3511\n",
      "Epoch 404/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4932 - mse: 5.4932 - val_loss: 7.3266 - val_mse: 7.3266\n",
      "Epoch 405/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4894 - mse: 5.4894 - val_loss: 7.3044 - val_mse: 7.3044\n",
      "Epoch 406/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4866 - mse: 5.4866 - val_loss: 7.2642 - val_mse: 7.2642\n",
      "Epoch 407/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4729 - mse: 5.4729 - val_loss: 7.3159 - val_mse: 7.3159\n",
      "Epoch 408/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4804 - mse: 5.4804 - val_loss: 7.3511 - val_mse: 7.3511\n",
      "Epoch 409/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4886 - mse: 5.4886 - val_loss: 7.3529 - val_mse: 7.3529\n",
      "Epoch 410/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.4862 - mse: 5.4862 - val_loss: 7.3066 - val_mse: 7.3066\n",
      "Epoch 411/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.4691 - mse: 5.4691 - val_loss: 7.1561 - val_mse: 7.1561\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4688 - mse: 5.4688 - val_loss: 7.0097 - val_mse: 7.0097\n",
      "Epoch 413/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.4757 - mse: 5.4757 - val_loss: 6.9395 - val_mse: 6.9395\n",
      "Epoch 414/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.4817 - mse: 5.4817 - val_loss: 6.9256 - val_mse: 6.9256\n",
      "Epoch 415/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4770 - mse: 5.4770 - val_loss: 6.9790 - val_mse: 6.9790\n",
      "Epoch 416/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4636 - mse: 5.4636 - val_loss: 7.0118 - val_mse: 7.0118\n",
      "Epoch 417/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4498 - mse: 5.4498 - val_loss: 7.0181 - val_mse: 7.0181\n",
      "Epoch 418/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4485 - mse: 5.4485 - val_loss: 7.0456 - val_mse: 7.0456\n",
      "Epoch 419/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4527 - mse: 5.4527 - val_loss: 7.0413 - val_mse: 7.0413\n",
      "Epoch 420/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4570 - mse: 5.4570 - val_loss: 7.0354 - val_mse: 7.0354\n",
      "Epoch 421/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4534 - mse: 5.4534 - val_loss: 7.0912 - val_mse: 7.0912\n",
      "Epoch 422/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4508 - mse: 5.4508 - val_loss: 7.0927 - val_mse: 7.0927\n",
      "Epoch 423/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4361 - mse: 5.4361 - val_loss: 7.0123 - val_mse: 7.0123\n",
      "Epoch 424/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.4575 - mse: 5.4575 - val_loss: 6.9206 - val_mse: 6.9206\n",
      "Epoch 425/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4677 - mse: 5.4677 - val_loss: 6.8728 - val_mse: 6.8728\n",
      "Epoch 426/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4796 - mse: 5.4796 - val_loss: 6.8778 - val_mse: 6.8778\n",
      "Epoch 427/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4563 - mse: 5.4563 - val_loss: 6.9622 - val_mse: 6.9622\n",
      "Epoch 428/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4302 - mse: 5.4302 - val_loss: 7.0458 - val_mse: 7.0458\n",
      "Epoch 429/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4238 - mse: 5.4238 - val_loss: 7.1723 - val_mse: 7.1723\n",
      "Epoch 430/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4269 - mse: 5.4269 - val_loss: 7.2566 - val_mse: 7.2566\n",
      "Epoch 431/500\n",
      "294/294 [==============================] - 0s 68us/sample - loss: 5.4371 - mse: 5.4371 - val_loss: 7.3133 - val_mse: 7.3133\n",
      "Epoch 432/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4467 - mse: 5.4467 - val_loss: 7.2851 - val_mse: 7.2851\n",
      "Epoch 433/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4473 - mse: 5.4473 - val_loss: 7.1302 - val_mse: 7.1302\n",
      "Epoch 434/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4183 - mse: 5.4183 - val_loss: 7.0305 - val_mse: 7.0305\n",
      "Epoch 435/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4209 - mse: 5.4209 - val_loss: 6.9955 - val_mse: 6.9955\n",
      "Epoch 436/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4232 - mse: 5.4232 - val_loss: 6.9694 - val_mse: 6.9694\n",
      "Epoch 437/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4164 - mse: 5.4164 - val_loss: 6.9618 - val_mse: 6.9618\n",
      "Epoch 438/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.4087 - mse: 5.4087 - val_loss: 6.9983 - val_mse: 6.9983\n",
      "Epoch 439/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4062 - mse: 5.4062 - val_loss: 7.0444 - val_mse: 7.0444\n",
      "Epoch 440/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4128 - mse: 5.4128 - val_loss: 7.1155 - val_mse: 7.1155\n",
      "Epoch 441/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4218 - mse: 5.4218 - val_loss: 7.1149 - val_mse: 7.1149\n",
      "Epoch 442/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4235 - mse: 5.4235 - val_loss: 7.0797 - val_mse: 7.0797\n",
      "Epoch 443/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.4057 - mse: 5.4057 - val_loss: 7.0911 - val_mse: 7.0911\n",
      "Epoch 444/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4085 - mse: 5.4085 - val_loss: 7.0658 - val_mse: 7.0658\n",
      "Epoch 445/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3946 - mse: 5.3946 - val_loss: 7.0782 - val_mse: 7.0782\n",
      "Epoch 446/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3998 - mse: 5.3998 - val_loss: 7.1255 - val_mse: 7.1255\n",
      "Epoch 447/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.3893 - mse: 5.3893 - val_loss: 7.1327 - val_mse: 7.1327\n",
      "Epoch 448/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3932 - mse: 5.3932 - val_loss: 7.0904 - val_mse: 7.0904\n",
      "Epoch 449/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3903 - mse: 5.3903 - val_loss: 7.1111 - val_mse: 7.1111\n",
      "Epoch 450/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3915 - mse: 5.3915 - val_loss: 7.1111 - val_mse: 7.1111\n",
      "Epoch 451/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3968 - mse: 5.3968 - val_loss: 7.1284 - val_mse: 7.1284\n",
      "Epoch 452/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.4023 - mse: 5.4023 - val_loss: 7.1576 - val_mse: 7.1576\n",
      "Epoch 453/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3920 - mse: 5.3920 - val_loss: 7.0917 - val_mse: 7.0917\n",
      "Epoch 454/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3866 - mse: 5.3866 - val_loss: 7.0202 - val_mse: 7.0202\n",
      "Epoch 455/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3787 - mse: 5.3787 - val_loss: 7.0062 - val_mse: 7.0062\n",
      "Epoch 456/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3775 - mse: 5.3775 - val_loss: 7.0031 - val_mse: 7.0031\n",
      "Epoch 457/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3764 - mse: 5.3764 - val_loss: 6.9849 - val_mse: 6.9849\n",
      "Epoch 458/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3709 - mse: 5.3709 - val_loss: 7.0154 - val_mse: 7.0154\n",
      "Epoch 459/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3698 - mse: 5.3698 - val_loss: 7.0601 - val_mse: 7.0601\n",
      "Epoch 460/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3598 - mse: 5.3598 - val_loss: 7.1288 - val_mse: 7.1288\n",
      "Epoch 461/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3642 - mse: 5.3642 - val_loss: 7.1800 - val_mse: 7.1800\n",
      "Epoch 462/500\n",
      "294/294 [==============================] - 0s 102us/sample - loss: 5.3733 - mse: 5.3733 - val_loss: 7.1981 - val_mse: 7.1981\n",
      "Epoch 463/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3741 - mse: 5.3741 - val_loss: 7.1905 - val_mse: 7.1905\n",
      "Epoch 464/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3684 - mse: 5.3684 - val_loss: 7.1117 - val_mse: 7.1117\n",
      "Epoch 465/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3537 - mse: 5.3537 - val_loss: 7.0459 - val_mse: 7.0459\n",
      "Epoch 466/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3446 - mse: 5.3446 - val_loss: 6.9422 - val_mse: 6.9422\n",
      "Epoch 467/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.4026 - mse: 5.4026 - val_loss: 6.8563 - val_mse: 6.8563\n",
      "Epoch 468/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3743 - mse: 5.3743 - val_loss: 6.9299 - val_mse: 6.9299\n",
      "Epoch 469/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3477 - mse: 5.3477 - val_loss: 7.0003 - val_mse: 7.0003\n",
      "Epoch 470/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3483 - mse: 5.3483 - val_loss: 7.0713 - val_mse: 7.0713\n",
      "Epoch 471/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3545 - mse: 5.3545 - val_loss: 7.1462 - val_mse: 7.1462\n",
      "Epoch 472/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3591 - mse: 5.3591 - val_loss: 7.1578 - val_mse: 7.1578\n",
      "Epoch 473/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3536 - mse: 5.3536 - val_loss: 7.1796 - val_mse: 7.1796\n",
      "Epoch 474/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3533 - mse: 5.3533 - val_loss: 7.1162 - val_mse: 7.1162\n",
      "Epoch 475/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3443 - mse: 5.3443 - val_loss: 7.1009 - val_mse: 7.1009\n",
      "Epoch 476/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3388 - mse: 5.3388 - val_loss: 7.0837 - val_mse: 7.0837\n",
      "Epoch 477/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3328 - mse: 5.3328 - val_loss: 7.1214 - val_mse: 7.1214\n",
      "Epoch 478/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3440 - mse: 5.3440 - val_loss: 7.1481 - val_mse: 7.1481\n",
      "Epoch 479/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3427 - mse: 5.3427 - val_loss: 7.1283 - val_mse: 7.1283\n",
      "Epoch 480/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3415 - mse: 5.3415 - val_loss: 7.1649 - val_mse: 7.1649\n",
      "Epoch 481/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3294 - mse: 5.3294 - val_loss: 7.1674 - val_mse: 7.1674\n",
      "Epoch 482/500\n",
      "294/294 [==============================] - 0s 71us/sample - loss: 5.3215 - mse: 5.3215 - val_loss: 7.1926 - val_mse: 7.1926\n",
      "Epoch 483/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3207 - mse: 5.3207 - val_loss: 7.2242 - val_mse: 7.2242\n",
      "Epoch 484/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3192 - mse: 5.3192 - val_loss: 7.2725 - val_mse: 7.2725\n",
      "Epoch 485/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3247 - mse: 5.3247 - val_loss: 7.3369 - val_mse: 7.3369\n",
      "Epoch 486/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3259 - mse: 5.3259 - val_loss: 7.3770 - val_mse: 7.3770\n",
      "Epoch 487/500\n",
      "294/294 [==============================] - 0s 85us/sample - loss: 5.3290 - mse: 5.3290 - val_loss: 7.3830 - val_mse: 7.3830\n",
      "Epoch 488/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3205 - mse: 5.3205 - val_loss: 7.3490 - val_mse: 7.3490\n",
      "Epoch 489/500\n",
      "294/294 [==============================] - 0s 82us/sample - loss: 5.3135 - mse: 5.3135 - val_loss: 7.2942 - val_mse: 7.2942\n",
      "Epoch 490/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.3234 - mse: 5.3234 - val_loss: 7.1987 - val_mse: 7.1987\n",
      "Epoch 491/500\n",
      "294/294 [==============================] - 0s 88us/sample - loss: 5.3086 - mse: 5.3086 - val_loss: 7.1880 - val_mse: 7.1880\n",
      "Epoch 492/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3034 - mse: 5.3034 - val_loss: 7.1447 - val_mse: 7.1447\n",
      "Epoch 493/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3042 - mse: 5.3042 - val_loss: 7.1198 - val_mse: 7.1198\n",
      "Epoch 494/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.2997 - mse: 5.2997 - val_loss: 7.0676 - val_mse: 7.0676\n",
      "Epoch 495/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3045 - mse: 5.3045 - val_loss: 7.0387 - val_mse: 7.0387\n",
      "Epoch 496/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3011 - mse: 5.3011 - val_loss: 7.0218 - val_mse: 7.0218\n",
      "Epoch 497/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.3004 - mse: 5.3004 - val_loss: 6.9963 - val_mse: 6.9963\n",
      "Epoch 498/500\n",
      "294/294 [==============================] - 0s 78us/sample - loss: 5.2988 - mse: 5.2988 - val_loss: 6.9536 - val_mse: 6.9536\n",
      "Epoch 499/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3099 - mse: 5.3099 - val_loss: 6.8840 - val_mse: 6.8840\n",
      "Epoch 500/500\n",
      "294/294 [==============================] - 0s 75us/sample - loss: 5.3084 - mse: 5.3084 - val_loss: 6.8941 - val_mse: 6.8941\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=500, validation_data=(X_test, y_test),\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.894109572683062, 6.8941097]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801505543455753"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2010b61b400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(X_test[:, 0], y_test, c='b', label=\"true\")\n",
    "plt.scatter(X_test[:, 0], y_predict, c='r', label=\"prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
