{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# 심층 합성곱 생성적 적대 신경망 (Deep Convolutional Generative Adversarial Networks, DCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MbKJY38Puy9"
   },
   "source": [
    "## 생성적 적대 신경망(GANs) \n",
    "\n",
    "- [생성적 적대 신경망](https://arxiv.org/abs/1406.2661) (Generative Adversarial Networks, GANs)은 요즘 컴퓨터 과학에서 가장 흥미로운 아이디어 중 하나  \n",
    "- 두개의 모델이 적대적인 과정을 통해 동시에 훈련  \n",
    "- *생성자* (\"예술가\")는 진짜처럼 보이는 이미지를 생성하도록 배우는 와중에, *감별자* (\"예술비평가\")는 가짜의 이미지로부터 진짜를 구별하게 되는 것을 배우게 됨\n",
    "\n",
    "![생성자와 감별자를 그린 도표](https://tensorflow.org/tutorials/generative/images/gan1.png)\n",
    "\n",
    "\n",
    "\n",
    "- 훈련과정 동안 *생성자*는 점차 실제같은 이미지를 더 잘 생성  \n",
    "- *감별자*는 점차 진짜와 가짜를 더 잘 구별  \n",
    "- 이 과정은 *감별자*가 가짜 이미지에서 진짜 이미지를 더이상 구별하지 못하게 될때, 평형상태에 도달\n",
    "\n",
    "![생성자와 감별자를 그린 두번째 도표](https://tensorflow.org/tutorials/generative/images/gan2.png)\n",
    "\n",
    "- 이 과정을 MNIST 데이터를 이용하여 구현  \n",
    "- 아래의 애니메이션은 50 에포크(epoch)동안 훈련한 *생성자*가 생성해낸 연속된 이미지들을 보여줌  \n",
    "- 이미지들은 랜덤한 잡음으로 부터 시작되었고, 점차 시간이 지남에 따라 손으로 쓴 숫자들을 닮아가게 됨\n",
    "\n",
    "![출력 예시](https://tensorflow.org/images/gan/dcgan.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZKbyU2-AiY-"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wx-zNbLqB4K8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YzTlj4YdCip_"
   },
   "outputs": [],
   "source": [
    "# GIF를 만들기위해 설치\n",
    "#!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "#import glob\n",
    "#import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### 데이터셋 로딩 및 준비\n",
    "- 생성자와 감별자를 훈련하기위해 MNIST 데이터셋을 사용  \n",
    "- 생성자는 손글씨 숫자 데이터를 닮은 숫자들을 생성할 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4fYMGxGhrna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist dataset load\n",
    "#(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFC2ghIdiZYE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# 이미지에 dimension 더해주고 [-1, 1]로 정규화\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 \n",
    "\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S4PIDhoDLbsZ"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yKCCQOoJ7cn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 28, 28, 1), types: tf.float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 배치를 만들고 섞음\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pxv2sUnnm3U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1138cdfc9e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[100].reshape(28, 28), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## 모델 만들기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tEyxE-GMC48"
   },
   "source": [
    "### 생성자\n",
    "\n",
    "- 생성자는 시드값 (seed; 랜덤한 잡음)으로부터 CNN 의 역순으로 이미지를 생성하기 위해, `tf.keras.layers.Conv2DTranspose` (inverse Convolution 을 통한 upsampling) 층을 이용  \n",
    "- stride=(2, 2) 일 경우 dimension 이 2 배로 upsampling 됨\n",
    "- 처음 `Dense`층은 시드값을 인풋으로 받음  \n",
    "- 그 다음 원하는 사이즈 28x28x1의 이미지가 나오도록 Conv2DTranspose 를 이용한 업샘플링을 여러번 함  \n",
    "- tanh를 사용하는 마지막 층을 제외한 나머지 각 층마다 활성함수로 `tf.keras.layers.LeakyReLU`을 사용하고 있음을 주목할 것\n",
    "\n",
    "<img src=\"GAN_Generator.png\" width=\"700\">\n",
    "\n",
    "- \"same\" padding and stride = 1, the output is the same size  \n",
    "- \"same\" padding and stride = 2, the output is double the size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, \n",
    "                           input_shape=(100,)))   # seed 를 입력으로 받음, 출력 12544\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)          # 배치사이즈로 None 추가\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), \n",
    "                                     strides=(1, 1), padding='same', use_bias=False))  \n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), \n",
    "                                     strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "(아직 훈련이 되지않은) 생성자를 이용해 이미지를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OiSikY24nm3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12544)             1254400   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12544)             50176     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(1, 100), b.shape=(100, 12544), m=1, n=12544, k=100 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-92673a09ce75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgenerated_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    254\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6124\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6126\u001b[1;33m       \u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6127\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6128\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf_20\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(1, 100), b.shape=(100, 12544), m=1, n=12544, k=100 [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "print(generated_image.shape)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### 감별자 \n",
    "- 감별자는 합성곱 신경망(Convolutional Neural Network, CNN) 기반의 이미지 분류기\n",
    "- MNIST dataset 은 input_shape (28, 28, 1)  \n",
    "- sigmoid output 은 probability scalar 값  \n",
    "- CNN 과의 차이 : pooling layer 없고, stride 를 통하여 downsampling  \n",
    "\n",
    "<img src=\"GAN_Discriminator.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), \n",
    "                            strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhPneagzCaQv"
   },
   "source": [
    "- (아직까지 훈련이 되지 않은) 감별자를 사용하여, 생성된 이미지가 진짜인지 가짜인지 판별  \n",
    "- 모델은 진짜 이미지에는 양수의 값 (positive values)을, 가짜 이미지에는 음수의 값 (negative values)을 출력하도록 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UxUOZ_Nbnm3h"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_discriminator_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d74f10fb0b25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdiscriminator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_discriminator_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_discriminator_model' is not defined"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## 손실함수와 옵티마이저 정의\n",
    "- 두 모델의 손실함수와 옵티마이저를 정의  \n",
    "- Discriminator 의 output 이 sigmoid 이므로, binary crossentropy 를 loss function 으로 사용 \n",
    "- from_logits=True 로 지정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "### 감별자 손실함수 \n",
    "\n",
    "- 감별자가 가짜 이미지에서 얼마나 진짜 이미지를 잘 판별하는지 수치화하는 함수  \n",
    "- 진짜 이미지에 대한 감별자의 예측과 1로 이루어진 행렬을 비교하고, 가짜 (생성된) 이미지에 대한 감별자의 예측과 0으로 이루어진 행렬을 비교  \n",
    "- shape 은 (256, 1) $\\rightarrow$ BATCHSIZE\n",
    "- real image 는 label [11111..111], fake image 는 label [00000....000] 이 ground truth  \n",
    "- discriminator 는 real 은 real 로, fake 는 fake 로 바르게 판별해야 하므로 real_loss + fake_loss 가 minimize 되도록 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "### 생성자 손실함수\n",
    "\n",
    "- 감별자를 얼마나 잘 속였는지에 대해 수치화  \n",
    "- 직관적으로 생성자가 원활히 수행되고 있다면, 감별자는 가짜 이미지를 진짜 (또는 1)로 분류를 할 것임. \n",
    "- 여기서 우리는 생성된 이미지에 대한 감별자의 결정(fake_output)을 1로 이루어진 행렬과 비교를 할 것임 (감별자가 감별한 결과가 모두 1 이 되어야 생성자가 감별자를 완벽히 속인 것임)\n",
    "- fake_output = discriminator(generated_images, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgIc7i0th_Iu"
   },
   "source": [
    "### 감별자와 생성자는 따로 훈련되기 때문에, 감별자와 생성자의 옵티마이저는 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWtinsGDPJlV"
   },
   "source": [
    "### 체크포인트 저장\n",
    "\n",
    "- optimizer 와 model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEGjn3b5tPi9"
   },
   "outputs": [],
   "source": [
    "tf.train.Checkpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA1w-7s2POEy"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## 훈련 루프 정의\n",
    "\n",
    "- 훈련 루프는 생성자가 입력으로 랜덤시드를 받는 것으로부터 시작  \n",
    "- 그 시드값을 사용하여 이미지를 생성  \n",
    "- 감별자를 사용하여 (훈련 세트에서 갖고온) 진짜 이미지와 (생성자가 생성해낸) 가짜이미지를 분류  \n",
    "- 각 모델의 손실을 계산하고, 그래디언트 (gradients)를 사용해 생성자와 감별자를 업데이트\n",
    "<img src=\"adverseModel.png\" width=\"500\">\n",
    "\n",
    "## Training\n",
    "\n",
    "<img src=\"GANtraining.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# 이 시드를 시간이 지나도 재활용 (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "# `tf.function` 데코레이터는 함수를 \"컴파일\"\n",
    "# 두개 module 의 gradient 를 따로 tracking 함\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)     # noise 에서 fake image 생성 \n",
    "\n",
    "        real_output = discriminator(images, training=True)       # real image 에 대한 감별자의 output\n",
    "        fake_output = discriminator(generated_images, training=True)  # fake image 에 대한 감별자의 output\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)   # fake image 에 대한 감별자의 output 을 all 1 로 만들기 위한 생성자 손실함수\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)  # real image 와 fake image 의 total loss 를 minimize 하기 위한 감별자 손실함수\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)  # 손실함수와 trainable parameter 지정\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)    \n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))   # gradient update\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # GIF를 위한 이미지를 바로 생성\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        # 15 에포크가 지날 때마다 모델을 저장\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "        print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
    "        \n",
    "    # 마지막 에포크가 끝난 후 생성\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2aFF7Hk3XdeW"
   },
   "source": [
    "**이미지 생성 및 저장**\n",
    "\n",
    "-`training`이 False로 맞춰진 것을 주목. 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "## 모델 훈련\n",
    "- 위에 정의된 `train()` 메서드를 생성자와 감별자를 동시에 훈련하기 위해 호출  \n",
    "- 생성적 적대 신경망을 학습하는 것은 매우 까다로울 수 있dma. 생성자와 감별자가 서로를 제압하지 않는 것이 중요 (예를 들어 학습률이 비슷하면 한쪽이 우세해짐.)\n",
    "- 훈련 초반부에는 생성된 이미지는 랜덤한 노이즈처럼 보이나 훈련이 진행될수록, 생성된 숫자는 점차 진짜처럼 보임  \n",
    "- 약 50 에포크가 지난 후, MNIST 숫자와 닮은 이미지가 생성  \n",
    "- 코랩에서 기본 설정으로 실행하면, 에포크마다 1분정도 소요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly3UN0SLLY2l"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfM4YcPVPkNO"
   },
   "source": [
    "마지막 체크포인트를 복구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XhXsd0srPo8c"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7neLmBBhxbgR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "## GIF 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "# 에포크 숫자를 사용하여 하나의 이미지를 보여준다\n",
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TMHTuisnm4J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "99-93.DCGAN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
