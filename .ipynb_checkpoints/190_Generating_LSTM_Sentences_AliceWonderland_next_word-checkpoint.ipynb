{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3SMFJYftfEs"
   },
   "source": [
    "# 190. Keras API 와 LSTM 을 이용한 이상한 나라의 Alice 문장 생성기\n",
    "\n",
    "- next word 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xQWk90P4thyK",
    "outputId": "0e834202-a363-4ad8-97fc-33d9939290e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asn1fHFytfEu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "uP-mC7LTtfEx",
    "outputId": "1d51e227-1d4f-46b6-b8b8-7d6c0d4f2d5c"
   },
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', \"http://www.gutenberg.org/files/11/11.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SvrmXp25tfEz",
    "outputId": "c455d87a-fe37-44bc-eca4-23d97cacedb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"project gutenberg's alice's adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever.  you may copy it, give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www.gutenberg.org title: alice's adventures in wonderland author: lewis carroll posting date: june 25, 2008 [ebook #11] release date: march, 1994 [last updated: december 20, 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3.0 chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought alice 'without pi\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = open(path_to_file)\n",
    "texts = r.readlines()\n",
    "lines = []\n",
    "\n",
    "for line in texts:\n",
    "    line = line.strip().lower()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "\n",
    "text = \" \".join(lines)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1RuGgWAmtfE2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "corpus = re.split('[,.]', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "RyUJ7MxNtfE4",
    "outputId": "d9e1b1ab-433f-4563-e6d0-884b9de855af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"project gutenberg's alice's adventures in wonderland\",\n",
       " ' by lewis carroll this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever',\n",
       " '  you may copy it',\n",
       " ' give it away or re-use it under the terms of the project gutenberg license included with this ebook or online at www',\n",
       " 'gutenberg',\n",
       " \"org title: alice's adventures in wonderland author: lewis carroll posting date: june 25\",\n",
       " ' 2008 [ebook #11] release date: march',\n",
       " ' 1994 [last updated: december 20',\n",
       " \" 2011] language: english character set encoding: ascii *** start of this project gutenberg ebook alice's adventures in wonderland *** alice's adventures in wonderland lewis carroll the millennium fulcrum edition 3\",\n",
       " '0 chapter i']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mRzxcEeatfE6",
    "outputId": "a57fb735-3b2b-47a5-f2f8-268112b4db72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3338\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11, 'you'), (12, 'alice'), (13, 'was'), (14, 'i'), (15, 'that')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.index_word.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', 11), ('alice', 12), ('was', 13), ('i', 14), ('that', 15)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.word_index.items())[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQlBVvwitfE8"
   },
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "nI97Ln4atfE_",
    "outputId": "2899e068-07d3-4bbd-934f-1cba72e3deaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[48, 1303],\n",
       " [48, 1303, 248],\n",
       " [48, 1303, 248, 342],\n",
       " [48, 1303, 248, 342, 10],\n",
       " [48, 1303, 248, 342, 10, 481],\n",
       " [59, 815],\n",
       " [59, 815, 816],\n",
       " [59, 815, 816, 22],\n",
       " [59, 815, 816, 22, 443],\n",
       " [59, 815, 816, 22, 443, 31]]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(input_sequences))\n",
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "neKxP5KXtfFB",
    "outputId": "b02878dc-1048-4336-8025-ee84b44d02f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   48, 1303],\n",
       "       [   0,    0,    0, ...,   48, 1303,  248],\n",
       "       [   0,    0,    0, ..., 1303,  248,  342],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,  275,   40],\n",
       "       [   0,    0,    0, ...,  275,   40,  494],\n",
       "       [   0,    0,    0, ...,   40,  494,  621]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejnqC8LZtfFE"
   },
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02XRjp6htfFH"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[-1]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "CqJpy2c-tfFJ",
    "outputId": "267b6982-038c-4ab5-a5a0-255e79b9e1a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[   0    0    0 ...    0    0   48]\n",
      " [   0    0    0 ...    0   48 1303]\n",
      " [   0    0    0 ...   48 1303  248]\n",
      " ...\n",
      " [   0    0    0 ...    8 1317    4]\n",
      " [   0    0    0 ... 1317    4   17]\n",
      " [   0    0    0 ...    4   17   15]], shape=(256, 62), dtype=int32)\n",
      "\n",
      "tf.Tensor(\n",
      "[1303  248  342   10  481  815  816   22  443   31   24    1  151    6\n",
      "  704 1006   19   49  817    3   18  482   49 1304 1305  175  343    8\n",
      "    8  169   27 1306  151    8  203    1  204    6    1   48   44  258\n",
      " 1007   18   22  443   27  818   19  625 1826  248  342   10  481 1827\n",
      "  815  816 1828  819 1829 1830  443  820 1832  819  136  140 1307 1834\n",
      " 1308 1836  550 1309  196 1837 1008 1009    6   22   48   44  443  248\n",
      "  342   10  481  248  342   10  481  815  816    1 1838 1839 1310  373\n",
      "  344   14    1  110  705   12   13  274    4  115   29  551    6  405\n",
      "   59   17  483   20    1 1010    6  406  154    4   45  148   27  706\n",
      "    7   23 1011   68    1  374   17  483   13  821    8   23   49  822\n",
      "   27 1311   10    8   38   31    1  151    6    5  374   62   12 1841\n",
      "  822   27 1311    2   28    7   13 1012   10   17  407  375   16  121\n",
      "   16    7   57    1  552  162  155   17  484   29  707    3 1013    1\n",
      " 1312    6  485    5 1842 1843   58   25  823    1  626    6  205   39\n",
      "    3 1313    1 1844  315    5  156  110   18 1845  163  259  316   59\n",
      "   17   13  154   28   29 1314   10   15 1315   74   12   91    8   28\n",
      "   29   93   35    6    1   76    4  275    1  110   95    4  295  170\n",
      "  206  170   14  188   25  627    2   60    7   62    8  122 1316 1317\n",
      "    4   17   15    7], shape=(256,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = text_dataset.map(split_input_target).batch(256, drop_remainder=True)\n",
    "\n",
    "for input, target in dataset.take(1):\n",
    "  print(input)\n",
    "  print()\n",
    "  print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "w9vH8Y59ajYL",
    "outputId": "8d9da036-fb34-405b-ad0c-3c42dc419c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         333800    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 64)          34048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1669)              28373     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3338)              5574460   \n",
      "=================================================================\n",
      "Total params: 5,975,865\n",
      "Trainable params: 5,975,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AIg2f1HBxqof",
    "outputId": "f93649f3-a66f-4824-f9f3-8d4a3dac210d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "106/106 [==============================] - 3s 26ms/step - loss: 2.4098 - accuracy: 0.4901\n",
      "Epoch 2/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.4158 - accuracy: 0.4894\n",
      "Epoch 3/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.4152 - accuracy: 0.4888\n",
      "Epoch 4/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.4049 - accuracy: 0.4902\n",
      "Epoch 5/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3934 - accuracy: 0.4926\n",
      "Epoch 6/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3877 - accuracy: 0.4916\n",
      "Epoch 7/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3991 - accuracy: 0.4924\n",
      "Epoch 8/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3801 - accuracy: 0.4969\n",
      "Epoch 9/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3720 - accuracy: 0.4980\n",
      "Epoch 10/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3751 - accuracy: 0.4954\n",
      "Epoch 11/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3820 - accuracy: 0.4945\n",
      "Epoch 12/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3613 - accuracy: 0.5000\n",
      "Epoch 13/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3681 - accuracy: 0.4982\n",
      "Epoch 14/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3457 - accuracy: 0.4992\n",
      "Epoch 15/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3368 - accuracy: 0.5010\n",
      "Epoch 16/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3289 - accuracy: 0.5073\n",
      "Epoch 17/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3453 - accuracy: 0.4998\n",
      "Epoch 18/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3370 - accuracy: 0.5008\n",
      "Epoch 19/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3146 - accuracy: 0.5055\n",
      "Epoch 20/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.3155 - accuracy: 0.5092\n",
      "Epoch 21/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.3180 - accuracy: 0.5071\n",
      "Epoch 22/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2953 - accuracy: 0.5104\n",
      "Epoch 23/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2824 - accuracy: 0.5144\n",
      "Epoch 24/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2913 - accuracy: 0.5141\n",
      "Epoch 25/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2763 - accuracy: 0.5159\n",
      "Epoch 26/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2745 - accuracy: 0.5146\n",
      "Epoch 27/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2606 - accuracy: 0.5220\n",
      "Epoch 28/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2588 - accuracy: 0.5188\n",
      "Epoch 29/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2481 - accuracy: 0.5223\n",
      "Epoch 30/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2501 - accuracy: 0.5229\n",
      "Epoch 31/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2408 - accuracy: 0.5251\n",
      "Epoch 32/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2371 - accuracy: 0.5257\n",
      "Epoch 33/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2421 - accuracy: 0.5203\n",
      "Epoch 34/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2406 - accuracy: 0.5247\n",
      "Epoch 35/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2245 - accuracy: 0.5293\n",
      "Epoch 36/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2254 - accuracy: 0.5255\n",
      "Epoch 37/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.2190 - accuracy: 0.5280\n",
      "Epoch 38/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2311 - accuracy: 0.5283\n",
      "Epoch 39/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2215 - accuracy: 0.5286\n",
      "Epoch 40/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.2168 - accuracy: 0.5289\n",
      "Epoch 41/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1994 - accuracy: 0.5322\n",
      "Epoch 42/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1865 - accuracy: 0.5368\n",
      "Epoch 43/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1833 - accuracy: 0.5365\n",
      "Epoch 44/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1733 - accuracy: 0.5384\n",
      "Epoch 45/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1835 - accuracy: 0.5382\n",
      "Epoch 46/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1787 - accuracy: 0.5371\n",
      "Epoch 47/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1770 - accuracy: 0.5367\n",
      "Epoch 48/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1661 - accuracy: 0.5384\n",
      "Epoch 49/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1665 - accuracy: 0.5405\n",
      "Epoch 50/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1686 - accuracy: 0.5363\n",
      "Epoch 51/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1595 - accuracy: 0.5417\n",
      "Epoch 52/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1632 - accuracy: 0.5425\n",
      "Epoch 53/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1645 - accuracy: 0.5381\n",
      "Epoch 54/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1663 - accuracy: 0.5412\n",
      "Epoch 55/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1428 - accuracy: 0.5455\n",
      "Epoch 56/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1367 - accuracy: 0.5440\n",
      "Epoch 57/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1172 - accuracy: 0.5521\n",
      "Epoch 58/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1158 - accuracy: 0.5484\n",
      "Epoch 59/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1035 - accuracy: 0.5523\n",
      "Epoch 60/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1104 - accuracy: 0.5527\n",
      "Epoch 61/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1054 - accuracy: 0.5550\n",
      "Epoch 62/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1051 - accuracy: 0.5562\n",
      "Epoch 63/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1113 - accuracy: 0.5521\n",
      "Epoch 64/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1181 - accuracy: 0.5480\n",
      "Epoch 65/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.1151 - accuracy: 0.5484\n",
      "Epoch 66/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.1207 - accuracy: 0.5477\n",
      "Epoch 67/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.0940 - accuracy: 0.5527\n",
      "Epoch 68/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0902 - accuracy: 0.5541\n",
      "Epoch 69/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0980 - accuracy: 0.5524\n",
      "Epoch 70/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.0943 - accuracy: 0.5516\n",
      "Epoch 71/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0660 - accuracy: 0.5628\n",
      "Epoch 72/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0602 - accuracy: 0.5641\n",
      "Epoch 73/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0496 - accuracy: 0.5650\n",
      "Epoch 74/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0447 - accuracy: 0.5658\n",
      "Epoch 75/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0393 - accuracy: 0.5660\n",
      "Epoch 76/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.0610 - accuracy: 0.5608\n",
      "Epoch 77/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0618 - accuracy: 0.5629\n",
      "Epoch 78/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0749 - accuracy: 0.5594\n",
      "Epoch 79/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0980 - accuracy: 0.5522\n",
      "Epoch 80/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0366 - accuracy: 0.5652\n",
      "Epoch 81/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 2.0184 - accuracy: 0.5729\n",
      "Epoch 82/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0207 - accuracy: 0.5719\n",
      "Epoch 83/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0242 - accuracy: 0.5701\n",
      "Epoch 84/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0144 - accuracy: 0.5715\n",
      "Epoch 85/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 2.0054 - accuracy: 0.5760\n",
      "Epoch 86/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9950 - accuracy: 0.5770\n",
      "Epoch 87/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9946 - accuracy: 0.5781\n",
      "Epoch 88/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9977 - accuracy: 0.5752\n",
      "Epoch 89/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9748 - accuracy: 0.5812\n",
      "Epoch 90/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9905 - accuracy: 0.5759\n",
      "Epoch 91/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9832 - accuracy: 0.5782\n",
      "Epoch 92/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9857 - accuracy: 0.5780\n",
      "Epoch 93/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9771 - accuracy: 0.5810\n",
      "Epoch 94/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9707 - accuracy: 0.5807\n",
      "Epoch 95/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9705 - accuracy: 0.5807\n",
      "Epoch 96/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9633 - accuracy: 0.5852\n",
      "Epoch 97/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9663 - accuracy: 0.5837\n",
      "Epoch 98/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9596 - accuracy: 0.5814\n",
      "Epoch 99/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9665 - accuracy: 0.5821\n",
      "Epoch 100/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9548 - accuracy: 0.5828\n",
      "Epoch 101/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9434 - accuracy: 0.5863\n",
      "Epoch 102/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9322 - accuracy: 0.5890\n",
      "Epoch 103/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9334 - accuracy: 0.5895\n",
      "Epoch 104/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9330 - accuracy: 0.5892\n",
      "Epoch 105/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9515 - accuracy: 0.5844\n",
      "Epoch 106/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9382 - accuracy: 0.5856\n",
      "Epoch 107/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9412 - accuracy: 0.5833\n",
      "Epoch 108/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9305 - accuracy: 0.5898\n",
      "Epoch 109/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9254 - accuracy: 0.5890\n",
      "Epoch 110/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.9191 - accuracy: 0.5923\n",
      "Epoch 111/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9143 - accuracy: 0.5929\n",
      "Epoch 112/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9026 - accuracy: 0.5935\n",
      "Epoch 113/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8882 - accuracy: 0.5986\n",
      "Epoch 114/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8912 - accuracy: 0.5981\n",
      "Epoch 115/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8842 - accuracy: 0.6004\n",
      "Epoch 116/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9000 - accuracy: 0.5946\n",
      "Epoch 117/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8787 - accuracy: 0.6028\n",
      "Epoch 118/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8869 - accuracy: 0.5983\n",
      "Epoch 119/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8816 - accuracy: 0.6013\n",
      "Epoch 120/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8777 - accuracy: 0.6009\n",
      "Epoch 121/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8971 - accuracy: 0.5937\n",
      "Epoch 122/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.9027 - accuracy: 0.5939\n",
      "Epoch 123/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8875 - accuracy: 0.5968\n",
      "Epoch 124/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8680 - accuracy: 0.6033\n",
      "Epoch 125/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8527 - accuracy: 0.6044\n",
      "Epoch 126/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8499 - accuracy: 0.6069\n",
      "Epoch 127/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8809 - accuracy: 0.5961\n",
      "Epoch 128/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8565 - accuracy: 0.6021\n",
      "Epoch 129/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8479 - accuracy: 0.6051\n",
      "Epoch 130/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8549 - accuracy: 0.6058\n",
      "Epoch 131/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8516 - accuracy: 0.6057\n",
      "Epoch 132/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8384 - accuracy: 0.6091\n",
      "Epoch 133/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8319 - accuracy: 0.6108\n",
      "Epoch 134/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.8451 - accuracy: 0.6027\n",
      "Epoch 135/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8396 - accuracy: 0.6096\n",
      "Epoch 136/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8297 - accuracy: 0.6082\n",
      "Epoch 137/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8313 - accuracy: 0.6097\n",
      "Epoch 138/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8632 - accuracy: 0.6033\n",
      "Epoch 139/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8707 - accuracy: 0.5994\n",
      "Epoch 140/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8392 - accuracy: 0.6072\n",
      "Epoch 141/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8140 - accuracy: 0.6137\n",
      "Epoch 142/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7992 - accuracy: 0.6160\n",
      "Epoch 143/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8162 - accuracy: 0.6149\n",
      "Epoch 144/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8389 - accuracy: 0.6081\n",
      "Epoch 145/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8548 - accuracy: 0.6015\n",
      "Epoch 146/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8097 - accuracy: 0.6155\n",
      "Epoch 147/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7931 - accuracy: 0.6181\n",
      "Epoch 148/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7849 - accuracy: 0.6212\n",
      "Epoch 149/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7829 - accuracy: 0.6200\n",
      "Epoch 150/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7766 - accuracy: 0.6229\n",
      "Epoch 151/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7698 - accuracy: 0.6247\n",
      "Epoch 152/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7835 - accuracy: 0.6211\n",
      "Epoch 153/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7969 - accuracy: 0.6199\n",
      "Epoch 154/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8150 - accuracy: 0.6100\n",
      "Epoch 155/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7754 - accuracy: 0.6222\n",
      "Epoch 156/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7665 - accuracy: 0.6271\n",
      "Epoch 157/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7756 - accuracy: 0.6224\n",
      "Epoch 158/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7682 - accuracy: 0.6228\n",
      "Epoch 159/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7660 - accuracy: 0.6233\n",
      "Epoch 160/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7536 - accuracy: 0.6254\n",
      "Epoch 161/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7488 - accuracy: 0.6293\n",
      "Epoch 162/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7538 - accuracy: 0.6253\n",
      "Epoch 163/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7597 - accuracy: 0.6263\n",
      "Epoch 164/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7464 - accuracy: 0.6295\n",
      "Epoch 165/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7680 - accuracy: 0.6221\n",
      "Epoch 166/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7406 - accuracy: 0.6298\n",
      "Epoch 167/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7307 - accuracy: 0.6320\n",
      "Epoch 168/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7375 - accuracy: 0.6290\n",
      "Epoch 169/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7266 - accuracy: 0.6320\n",
      "Epoch 170/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7252 - accuracy: 0.6347\n",
      "Epoch 171/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7213 - accuracy: 0.6338\n",
      "Epoch 172/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7149 - accuracy: 0.6344\n",
      "Epoch 173/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7159 - accuracy: 0.6341\n",
      "Epoch 174/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7111 - accuracy: 0.6346\n",
      "Epoch 175/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7094 - accuracy: 0.6344\n",
      "Epoch 176/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7014 - accuracy: 0.6427\n",
      "Epoch 177/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6977 - accuracy: 0.6400\n",
      "Epoch 178/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7109 - accuracy: 0.6328\n",
      "Epoch 179/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7363 - accuracy: 0.6289\n",
      "Epoch 180/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7347 - accuracy: 0.6320\n",
      "Epoch 181/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7037 - accuracy: 0.6383\n",
      "Epoch 182/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7212 - accuracy: 0.6326\n",
      "Epoch 183/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7913 - accuracy: 0.6137\n",
      "Epoch 184/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7872 - accuracy: 0.6148\n",
      "Epoch 185/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.8454 - accuracy: 0.6045\n",
      "Epoch 186/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7580 - accuracy: 0.6236\n",
      "Epoch 187/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7204 - accuracy: 0.6310\n",
      "Epoch 188/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7082 - accuracy: 0.6372\n",
      "Epoch 189/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6918 - accuracy: 0.6418\n",
      "Epoch 190/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6824 - accuracy: 0.6406\n",
      "Epoch 191/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6920 - accuracy: 0.6397\n",
      "Epoch 192/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6843 - accuracy: 0.6442\n",
      "Epoch 193/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6784 - accuracy: 0.6443\n",
      "Epoch 194/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6652 - accuracy: 0.6454\n",
      "Epoch 195/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6650 - accuracy: 0.6453\n",
      "Epoch 196/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6736 - accuracy: 0.6426\n",
      "Epoch 197/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6636 - accuracy: 0.6473\n",
      "Epoch 198/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6568 - accuracy: 0.6482\n",
      "Epoch 199/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6460 - accuracy: 0.6488\n",
      "Epoch 200/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6474 - accuracy: 0.6491\n",
      "Epoch 201/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6536 - accuracy: 0.6492\n",
      "Epoch 202/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6520 - accuracy: 0.6468\n",
      "Epoch 203/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6469 - accuracy: 0.6505\n",
      "Epoch 204/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6397 - accuracy: 0.6517\n",
      "Epoch 205/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6262 - accuracy: 0.6551\n",
      "Epoch 206/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6242 - accuracy: 0.6559\n",
      "Epoch 207/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6301 - accuracy: 0.6547\n",
      "Epoch 208/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6261 - accuracy: 0.6543\n",
      "Epoch 209/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6335 - accuracy: 0.6541\n",
      "Epoch 210/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6290 - accuracy: 0.6530\n",
      "Epoch 211/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6217 - accuracy: 0.6534\n",
      "Epoch 212/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6405 - accuracy: 0.6526\n",
      "Epoch 213/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6775 - accuracy: 0.6425\n",
      "Epoch 214/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.7856 - accuracy: 0.6175\n",
      "Epoch 215/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.7116 - accuracy: 0.6348\n",
      "Epoch 216/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6633 - accuracy: 0.6446\n",
      "Epoch 217/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6304 - accuracy: 0.6551\n",
      "Epoch 218/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6195 - accuracy: 0.6559\n",
      "Epoch 219/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6024 - accuracy: 0.6613\n",
      "Epoch 220/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5985 - accuracy: 0.6606\n",
      "Epoch 221/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6055 - accuracy: 0.6610\n",
      "Epoch 222/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6143 - accuracy: 0.6579\n",
      "Epoch 223/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6240 - accuracy: 0.6525\n",
      "Epoch 224/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6027 - accuracy: 0.6605\n",
      "Epoch 225/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5922 - accuracy: 0.6617\n",
      "Epoch 226/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5841 - accuracy: 0.6640\n",
      "Epoch 227/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5895 - accuracy: 0.6614\n",
      "Epoch 228/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5867 - accuracy: 0.6640\n",
      "Epoch 229/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5900 - accuracy: 0.6640\n",
      "Epoch 230/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5773 - accuracy: 0.6647\n",
      "Epoch 231/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6149 - accuracy: 0.6589\n",
      "Epoch 232/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6505 - accuracy: 0.6478\n",
      "Epoch 233/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6012 - accuracy: 0.6580\n",
      "Epoch 234/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.6113 - accuracy: 0.6564\n",
      "Epoch 235/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5978 - accuracy: 0.6617\n",
      "Epoch 236/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5783 - accuracy: 0.6651\n",
      "Epoch 237/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5815 - accuracy: 0.6647\n",
      "Epoch 238/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5719 - accuracy: 0.6656\n",
      "Epoch 239/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5608 - accuracy: 0.6687\n",
      "Epoch 240/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5644 - accuracy: 0.6677\n",
      "Epoch 241/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5541 - accuracy: 0.6720\n",
      "Epoch 242/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5659 - accuracy: 0.6691\n",
      "Epoch 243/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5637 - accuracy: 0.6697\n",
      "Epoch 244/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5789 - accuracy: 0.6626\n",
      "Epoch 245/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5555 - accuracy: 0.6694\n",
      "Epoch 246/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5470 - accuracy: 0.6723\n",
      "Epoch 247/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5453 - accuracy: 0.6737\n",
      "Epoch 248/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5492 - accuracy: 0.6692\n",
      "Epoch 249/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5406 - accuracy: 0.6727\n",
      "Epoch 250/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5345 - accuracy: 0.6774\n",
      "Epoch 251/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5311 - accuracy: 0.6754\n",
      "Epoch 252/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5459 - accuracy: 0.6697\n",
      "Epoch 253/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5345 - accuracy: 0.6730\n",
      "Epoch 254/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5281 - accuracy: 0.6763\n",
      "Epoch 255/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5353 - accuracy: 0.6756\n",
      "Epoch 256/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5637 - accuracy: 0.6671\n",
      "Epoch 257/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6457 - accuracy: 0.6501\n",
      "Epoch 258/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6890 - accuracy: 0.6362\n",
      "Epoch 259/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.6092 - accuracy: 0.6531\n",
      "Epoch 260/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5468 - accuracy: 0.6722\n",
      "Epoch 261/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5180 - accuracy: 0.6788\n",
      "Epoch 262/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5164 - accuracy: 0.6809\n",
      "Epoch 263/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5134 - accuracy: 0.6794\n",
      "Epoch 264/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5060 - accuracy: 0.6823\n",
      "Epoch 265/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5033 - accuracy: 0.6823\n",
      "Epoch 266/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5006 - accuracy: 0.6857\n",
      "Epoch 267/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4924 - accuracy: 0.6848\n",
      "Epoch 268/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4949 - accuracy: 0.6836\n",
      "Epoch 269/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4962 - accuracy: 0.6872\n",
      "Epoch 270/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4916 - accuracy: 0.6850\n",
      "Epoch 271/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4979 - accuracy: 0.6825\n",
      "Epoch 272/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5060 - accuracy: 0.6797\n",
      "Epoch 273/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5059 - accuracy: 0.6805\n",
      "Epoch 274/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5047 - accuracy: 0.6811\n",
      "Epoch 275/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5111 - accuracy: 0.6812\n",
      "Epoch 276/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5146 - accuracy: 0.6788\n",
      "Epoch 277/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.5232 - accuracy: 0.6753\n",
      "Epoch 278/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5599 - accuracy: 0.6672\n",
      "Epoch 279/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5344 - accuracy: 0.6743\n",
      "Epoch 280/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5190 - accuracy: 0.6762\n",
      "Epoch 281/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4910 - accuracy: 0.6846\n",
      "Epoch 282/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4876 - accuracy: 0.6867\n",
      "Epoch 283/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4788 - accuracy: 0.6855\n",
      "Epoch 284/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4727 - accuracy: 0.6888\n",
      "Epoch 285/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4769 - accuracy: 0.6883\n",
      "Epoch 286/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4631 - accuracy: 0.6937\n",
      "Epoch 287/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4666 - accuracy: 0.6920\n",
      "Epoch 288/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4629 - accuracy: 0.6913\n",
      "Epoch 289/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4740 - accuracy: 0.6871\n",
      "Epoch 290/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4803 - accuracy: 0.6877\n",
      "Epoch 291/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4716 - accuracy: 0.6874\n",
      "Epoch 292/300\n",
      "106/106 [==============================] - 3s 25ms/step - loss: 1.4598 - accuracy: 0.6937\n",
      "Epoch 293/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4513 - accuracy: 0.6955\n",
      "Epoch 294/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4648 - accuracy: 0.6920\n",
      "Epoch 295/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4612 - accuracy: 0.6945\n",
      "Epoch 296/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4929 - accuracy: 0.6840\n",
      "Epoch 297/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.5121 - accuracy: 0.6775\n",
      "Epoch 298/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4879 - accuracy: 0.6823\n",
      "Epoch 299/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4614 - accuracy: 0.6921\n",
      "Epoch 300/300\n",
      "106/106 [==============================] - 3s 24ms/step - loss: 1.4672 - accuracy: 0.6877\n",
      "CPU times: user 15min 46s, sys: 1min 31s, total: 17min 17s\n",
      "Wall time: 12min 57s\n"
     ]
    }
   ],
   "source": [
    " %%time\n",
    " history = model.fit(dataset, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "1fXTEO3GJ282",
    "outputId": "e49e05e3-fd68-4d1a-b5a0-7f146475a83a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MPTokoLYxCvI",
    "outputId": "16a9f8d8-8e1e-4511-bcb2-98aa12200024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope almost it ' said the mouse the sea before the jelly idea her where was me any access you'd any hungry confirmation or anywhere near a jury can oh sort of dogs his child and do not play works at the dodo sobbing a song in a crowd of child ' the queen knew the pool of the notice knave things hungry to jury that what i think i can hear which say it do lessons ' he said you here and when she asked to itself till 'why had it been not a obtaining a little nervous about it\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = tokenizer.index_word[predicted[0]]\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJzIYX4Fw574"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "973.Generating_LSTM_Sentences_AliceWonderland_next_word.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
